import pandas as pd
import os
import joblib
import torch
import numpy as np
import nibabel as nib
from sklearn.preprocessing import StandardScaler
from pathlib import Path
import warnings
from model2 import resnet18_3d  # ç¡®ä¿model.pyåœ¨ç›¸åŒç›®å½•æˆ–æ­£ç¡®è·¯å¾„

warnings.filterwarnings('ignore')

# ç‰¹å¾åˆ—è¡¨ï¼ˆåŒ…å«æ–°å¢çš„ä¸‰ä¸ªå¾®ç”Ÿç‰©ç‰¹å¾ï¼Œå…±11ä¸ªç‰¹å¾ï¼‰
COLUMN_ORDER = [
    'å§“å',
    'Periodontal pocket',  # 1. ç‰™å‘¨è¢‹æ·±åº¦
    'CAL',  # 2. ä¸´åºŠé™„ç€ä¸§å¤±
    'Missing teeth',  # 3. ç¼ºå¤±ç‰™æ•°
    'Occlusal',  # 4. å’¬åˆçŠ¶æ€
    'Looseness',  # 5. æœ€å¤§ç‰™é½¿æ¾åŠ¨åº¦
    'Root bifurcation lesion',  # 6. æœ€å¤§æ ¹åˆ†å‰ç—…å˜
    'Gingival condition',  # 7. ç‰™é¾ˆçŠ¶å†µ
    'inference_code',  # 8. ç¬¬8ä¸ªç‰¹å¾ï¼ˆå·²æ›¿æ¢ä¸ºinference_codeï¼‰
    'Porphyromonas_endodontalis',  # 9. æ–°å¢ç‰¹å¾ï¼šç‰™é«“åŸå•‰å•èƒèŒ
    'Porphyromonas_gingivalis',  # 10. æ–°å¢ç‰¹å¾ï¼šä¸­é—´å¯†èºæ—‹ä½“
    'Campylobacter_gracilis'  # 11. æ–°å¢ç‰¹å¾ï¼šçº¤ç»†å¼¯æ›²èŒ
]


def collect_patient_data():
    """æ”¶é›†æ‚£è€…ç‰™å‘¨ç‚ä¸´åºŠæ•°æ®ï¼ˆå«11ä¸ªç‰¹å¾ï¼‰ï¼Œå¼ºåŒ–æŒ‡æ ‡éªŒè¯"""
    patients = []
    while True:
        patient_name = input("è¯·è¾“å…¥æ‚£è€…å§“åï¼ˆè¾“å…¥qé€€å‡ºï¼‰ï¼š")
        if patient_name.lower() == 'q':
            break

        # å§“åéç©ºéªŒè¯
        if not patient_name.strip():
            print("é”™è¯¯ï¼šæ‚£è€…å§“åä¸èƒ½ä¸ºç©ºï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")
            continue

        # 1. ç‰™å‘¨è¢‹æ·±åº¦ï¼ˆæ­£æ•°ï¼‰
        while True:
            pocket_input = input("è¯·è¾“å…¥æ‚£è€…ç‰™å‘¨è¢‹æ·±åº¦ï¼ˆå•ä½ï¼šmmï¼Œç›´æ¥è¾“å…¥æ•°å­—ï¼‰ï¼š")
            try:
                periodontal_pocket = float(pocket_input)
                if periodontal_pocket <= 0:
                    print("é”™è¯¯ï¼šç‰™å‘¨è¢‹æ·±åº¦å¿…é¡»ä¸ºæ­£æ•°ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")
                else:
                    break
            except ValueError:
                print("é”™è¯¯ï¼šç‰™å‘¨è¢‹æ·±åº¦å¿…é¡»æ˜¯æ•°å­—ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")

        # 2. CALï¼ˆéè´Ÿæ•°ï¼‰
        while True:
            cal_input = input("è¯·è¾“å…¥æ‚£è€…ä¸´åºŠé™„ç€ä¸§å¤±ï¼ˆCALï¼Œå•ä½ï¼šmmï¼Œç›´æ¥è¾“å…¥æ•°å­—ï¼‰ï¼š")
            try:
                cal = float(cal_input)
                if cal < 0:
                    print("é”™è¯¯ï¼šä¸´åºŠé™„ç€ä¸§å¤±ä¸èƒ½ä¸ºè´Ÿæ•°ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")
                else:
                    break
            except ValueError:
                print("é”™è¯¯ï¼šä¸´åºŠé™„ç€ä¸§å¤±å¿…é¡»æ˜¯æ•°å­—ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")

        # 3. ç¼ºå¤±ç‰™æ•°ï¼ˆéè´Ÿæ•´æ•°ï¼‰
        while True:
            missing_teeth_input = input("è¯·è¾“å…¥æ‚£è€…ç¼ºå¤±ç‰™æ•°ï¼ˆç›´æ¥è¾“å…¥æ•´æ•°ï¼‰ï¼š")
            try:
                missing_teeth = int(missing_teeth_input)
                if missing_teeth < 0:
                    print("é”™è¯¯ï¼šç¼ºå¤±ç‰™æ•°ä¸èƒ½ä¸ºè´Ÿæ•°ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")
                else:
                    break
            except ValueError:
                print("é”™è¯¯ï¼šç¼ºå¤±ç‰™æ•°å¿…é¡»æ˜¯æ•´æ•°ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")

        # 4. å’¬åˆçŠ¶æ€ï¼ˆ0/1/2ï¼‰
        while True:
            occlusal_input = input(
                "è¯·è¾“å…¥å’¬åˆçŠ¶æ€ï¼ˆ0=æ— å¼‚å¸¸ï¼Œ1=ç¼ºç‰™å°‘äº4é¢—ä¸”ç‰™é½¿æ´»åŠ¨åº¦ä½ï¼Œ2=ç¼ºç‰™è¶…è¿‡4é¢—ä¸”å…¨å£ç‰™é½¿é«˜åº¦æ¾åŠ¨ï¼‰ï¼š")
            if occlusal_input in ['0', '1', '2']:
                occlusal = int(occlusal_input)
                break
            print("é”™è¯¯ï¼šè¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥0ã€1æˆ–2ã€‚")

        # 5. æœ€å¤§ç‰™é½¿æ¾åŠ¨åº¦ï¼ˆ0-3ï¼‰
        while True:
            looseness_input = input("è¯·è¾“å…¥æœ€å¤§ç‰™é½¿æ¾åŠ¨åº¦ï¼ˆ0=Noneï¼Œ1=Grade 1ï¼Œ2=Grade 2ï¼Œ3=Grade 3ï¼‰ï¼š")
            if looseness_input in ['0', '1', '2', '3']:
                looseness = int(looseness_input)
                break
            print("é”™è¯¯ï¼šè¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥0-3ä¹‹é—´çš„æ•°å­—ã€‚")

        # 6. æœ€å¤§æ ¹åˆ†å‰ç—…å˜ï¼ˆ0-3ï¼‰
        while True:
            bifurcation_input = input("è¯·è¾“å…¥æœ€å¤§æ ¹åˆ†å‰ç—…å˜ï¼ˆ0=Noneï¼Œ1=Grade 1ï¼Œ2=Grade 2ï¼Œ3=Grade 3ï¼‰ï¼š")
            if bifurcation_input in ['0', '1', '2', '3']:
                root_bifurcation = int(bifurcation_input)
                break
            print("é”™è¯¯ï¼šè¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥0-3ä¹‹é—´çš„æ•°å­—ã€‚")

        # 7. ç‰™é¾ˆçŠ¶å†µï¼ˆ0-3ï¼‰
        while True:
            gingival_input = input(
                "è¯·è¾“å…¥ç‰™é¾ˆçŠ¶å†µï¼ˆ0=Noneï¼Œ1=å¶å°”å‡ºè¡€æ— æ˜æ˜¾ä¸é€‚ï¼Œ2=é¢‘ç¹å‡ºè¡€å¶æœ‰æº¢è„“ä¼´è½»åº¦æ¾åŠ¨ï¼Œ3=æŒç»­å‡ºè¡€æº¢è„“ä¼´å’€åš¼å›°éš¾ï¼‰ï¼š")
            if gingival_input in ['0', '1', '2', '3']:
                gingival_condition = int(gingival_input)
                break
            print("é”™è¯¯ï¼šè¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥0-3ä¹‹é—´çš„æ•°å­—ã€‚")

        # 8. inference_codeç‰¹å¾çš„è¾“å…¥
        while True:
            print("\ninference_codeæ¥æºï¼š")
            print("1. æ‰‹åŠ¨è¾“å…¥")
            print("2. é€šè¿‡CTå½±åƒè‡ªåŠ¨æ¨ç†è·å–")
            inference_choice = input("è¯·é€‰æ‹©inference_codeè·å–æ–¹å¼ (1æˆ–2): ")

            if inference_choice == '1':
                inference_code_input = input("è¯·è¾“å…¥inference_codeï¼ˆæ•°å­—ï¼‰ï¼š")
                try:
                    inference_code = float(inference_code_input)
                    if inference_code < 0:
                        print("é”™è¯¯ï¼šinference_codeä¸èƒ½ä¸ºè´Ÿæ•°ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")
                    else:
                        break
                except ValueError:
                    print("é”™è¯¯ï¼šinference_codeå¿…é¡»æ˜¯æ•°å­—ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")
            elif inference_choice == '2':
                inference_code = run_ct_inference_pipeline()
                if inference_code is not None:
                    print(f"CTå½±åƒæ¨ç†ç»“æœ: inference_code = {inference_code}")
                    break
                else:
                    print("CTå½±åƒæ¨ç†å¤±è´¥ï¼Œè¯·é€‰æ‹©å…¶ä»–æ–¹å¼æˆ–é‡è¯•ã€‚")
            else:
                print("é”™è¯¯ï¼šè¯·è¾“å…¥1æˆ–2é€‰æ‹©è·å–æ–¹å¼ã€‚")

        # 9. Porphyromonas_endodontalis (ç‰™é«“åŸå•‰å•èƒèŒ)
        while True:
            pep_input = input("\nè¯·è¾“å…¥ç‰™é«“åŸå•‰å•èƒèŒ (Porphyromonas_endodontalis) æ•°å€¼ï¼š")
            try:
                pep = float(pep_input)
                if pep < 0:
                    print("é”™è¯¯ï¼šæ•°å€¼ä¸èƒ½ä¸ºè´Ÿæ•°ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")
                else:
                    break
            except ValueError:
                print("é”™è¯¯ï¼šå¿…é¡»è¾“å…¥æ•°å­—ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")

        # 10. Treponema_medium (ä¸­é—´å¯†èºæ—‹ä½“)
        while True:
            tm_input = input("è¯·è¾“å…¥ä¸­é—´å¯†èºæ—‹ä½“ (Treponema_medium) æ•°å€¼ï¼š")
            try:
                tm = float(tm_input)
                if tm < 0:
                    print("é”™è¯¯ï¼šæ•°å€¼ä¸èƒ½ä¸ºè´Ÿæ•°ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")
                else:
                    break
            except ValueError:
                print("é”™è¯¯ï¼šå¿…é¡»è¾“å…¥æ•°å­—ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")

        # 11. Campylobacter_gracilis (çº¤ç»†å¼¯æ›²èŒ)
        while True:
            cg_input = input("è¯·è¾“å…¥çº¤ç»†å¼¯æ›²èŒ (Campylobacter_gracilis) æ•°å€¼ï¼š")
            try:
                cg = float(cg_input)
                if cg < 0:
                    print("é”™è¯¯ï¼šæ•°å€¼ä¸èƒ½ä¸ºè´Ÿæ•°ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")
                else:
                    break
            except ValueError:
                print("é”™è¯¯ï¼šå¿…é¡»è¾“å…¥æ•°å­—ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")

        # æŒ‰11ä¸ªç‰¹å¾é¡ºåºç»„ç»‡æ•°æ®
        patients.append({
            'å§“å': patient_name,
            'Periodontal pocket': periodontal_pocket,
            'CAL': cal,
            'Missing teeth': missing_teeth,
            'Occlusal': occlusal,
            'Looseness': looseness,
            'Root bifurcation lesion': root_bifurcation,
            'Gingival condition': gingival_condition,
            'inference_code': inference_code,
            'Porphyromonas_endodontalis': pep,
            'Treponema_medium': tm,
            'Campylobacter_gracilis': cg
        })
        print(f"\næ‚£è€… {patient_name} çš„ç‰™å‘¨æ•°æ®ï¼ˆå«11ä¸ªç‰¹å¾ï¼‰å·²è®°å½•ã€‚")

    return patients


def save_to_excel(patients, file_path="patient_periodontal_data.xlsx"):
    """ä¿å­˜å«11ä¸ªç‰¹å¾çš„ç‰™å‘¨æ•°æ®åˆ°Excelï¼Œæ”¯æŒè¿½åŠ """
    if not patients:
        print("æ²¡æœ‰æ•°æ®å¯ä¿å­˜ã€‚")
        return

    df = pd.DataFrame(patients, columns=COLUMN_ORDER)

    if os.path.exists(file_path):
        try:
            existing_df = pd.read_excel(file_path)
            # ä¸ºæ—§æ•°æ®è¡¥å…¨ç¼ºå¤±çš„ç‰¹å¾åˆ—
            for col in COLUMN_ORDER:
                if col not in existing_df.columns:
                    existing_df[col] = None
            existing_df = existing_df.reindex(columns=COLUMN_ORDER)
            combined_df = pd.concat([existing_df, df], ignore_index=True)
            combined_df.to_excel(file_path, index=False)
            print(f"æ•°æ®ï¼ˆå«11ä¸ªç‰¹å¾ï¼‰å·²è¿½åŠ åˆ° {file_path}")
        except Exception as e:
            print(f"è¿½åŠ æ•°æ®æ—¶å‡ºé”™: {e}")
    else:
        try:
            df.to_excel(file_path, index=False)
            print(f"æ–°æ–‡ä»¶å·²åˆ›å»º: {file_path}ï¼ˆå«11ä¸ªç‰™å‘¨ç‚ä¸´åºŠç‰¹å¾ï¼‰")
        except Exception as e:
            print(f"åˆ›å»ºæ–‡ä»¶æ—¶å‡ºé”™: {e}")


# å®šä¹‰äºŒåˆ†ç±» Transformer æ¨¡å‹ï¼ˆç”¨äºåŒ¹é… junqun.pth æƒé‡ï¼‰
class PeriodontalTransformerClassifier(torch.nn.Module):
    def __init__(self, input_size=11, hidden_size=64, num_layers=1, num_classes=2, dropout=0.1):
        """
        å®Œå…¨åŒ¹é…æƒé‡æ–‡ä»¶çš„ Transformer æ¨¡å‹ç»“æ„ï¼š
        - input_size=11ï¼ˆ11ä¸ªç‰¹å¾ï¼‰
        - hidden_size=64ï¼ˆæƒé‡æ–‡ä»¶ä¸­å®é™…çš„éšè—å±‚ç»´åº¦ï¼‰
        - num_layers=1ï¼ˆæƒé‡æ–‡ä»¶ä¸­å®é™…çš„ç¼–ç å™¨å±‚æ•°ï¼‰
        - num_classes=2ï¼ˆäºŒåˆ†ç±»è¾“å‡ºï¼š0=è½»åº¦ï¼Œ1=é‡åº¦ï¼‰
        """
        super(PeriodontalTransformerClassifier, self).__init__()

        # 1. è¾“å…¥æŠ•å½±å±‚ï¼šåŒ¹é…æƒé‡æ–‡ä»¶çš„ [64, 11] ç»´åº¦
        self.input_proj = torch.nn.Sequential(
            torch.nn.Linear(input_size, hidden_size),  # [11, 64]
            torch.nn.LayerNorm(hidden_size)  # [64]
        )

        # 2. Transformer ç¼–ç å™¨å±‚ï¼ˆ1å±‚ï¼‰
        encoder_layer = torch.nn.TransformerEncoderLayer(
            d_model=hidden_size,  # 64
            nhead=8,  # å¤šå¤´æ³¨æ„åŠ›å¤´æ•°ï¼ˆ64/8=8ï¼Œç¬¦åˆç»´åº¦è¦æ±‚ï¼‰
            dim_feedforward=128,  # å‰é¦ˆç½‘ç»œç»´åº¦ï¼ˆæƒé‡æ–‡ä»¶ä¸­ä¸º128ï¼‰
            dropout=dropout,
            batch_first=True  # è¾“å…¥æ ¼å¼ï¼š[batch, seq_len, feature]
        )
        self.encoder = torch.nn.TransformerEncoder(encoder_layer, num_layers=num_layers)

        # 3. è¾“å‡ºæŠ•å½±å±‚ï¼šæ ¹æ®æƒé‡æ–‡ä»¶è°ƒæ•´ä¸ºæ­£ç¡®ç»“æ„
        # é”™è¯¯åˆ†æè¡¨æ˜ï¼Œoutput_proj.0 æ˜¯ä¸€ä¸ª LayerNormï¼Œè€Œä¸æ˜¯ Linearã€‚
        self.output_proj = torch.nn.Sequential(
            torch.nn.LayerNorm(hidden_size),  # output_proj.0, æƒé‡å½¢çŠ¶ä¸º [64]
            torch.nn.Linear(hidden_size, num_classes)  # output_proj.1, æƒé‡å½¢çŠ¶ä¸º [2, 64]
        )

    def forward(self, x):
        """å‰å‘ä¼ æ’­"""
        # è¾“å…¥æŠ•å½±ï¼š[batch, 1, 11] -> [batch, 1, 64]
        x = self.input_proj(x)

        # Transformer ç¼–ç ï¼š[batch, 1, 64] -> [batch, 1, 64]
        x = self.encoder(x)

        # å–åºåˆ—æœ€åä¸€ä¸ªæ—¶é—´æ­¥è¾“å‡ºï¼š[batch, 1, 64] -> [batch, 64]
        x = x[:, -1, :]

        # è¾“å‡ºæŠ•å½±ï¼š[batch, 64] -> [batch, 2]
        logits = self.output_proj(x)
        return logits


def load_and_predict(file_path="patient_periodontal_data.xlsx",
                     model_path=r"E:/D/ç½‘ç«™/è½¯ä»¶ç½‘ç«™æ¨¡å—/junqun.pth",  # äºŒåˆ†ç±»æ¨¡å‹æƒé‡è·¯å¾„
                     scaler_path="periodontal_scaler.pkl"):
    """åŠ è½½11ä¸ªç‰¹å¾çš„ç‰™å‘¨æ•°æ®ï¼Œç”¨äºŒåˆ†ç±»æ¨¡å‹é¢„æµ‹"""
    try:
        # 1. è¯»å–æ•°æ®å¹¶éªŒè¯11ä¸ªç‰¹å¾
        df = pd.read_excel(file_path)
        print(f"æˆåŠŸåŠ è½½ {len(df)} æ¡æ‚£è€…ç‰™å‘¨æ•°æ®ï¼ˆå«11ä¸ªç‰¹å¾æ ¡éªŒï¼‰")

        # 2. æå–è®­ç»ƒæ¨¡å‹å¯¹åº”çš„11ä¸ªç‰¹å¾
        required_features = [
            'Periodontal pocket', 'CAL', 'Missing teeth', 'Occlusal',
            'Looseness', 'Root bifurcation lesion', 'Gingival condition',
            'inference_code',
            'Porphyromonas_endodontalis', 'Treponema_medium', 'Campylobacter_gracilis'
        ]
        missing_features = [f for f in required_features if f not in df.columns]
        if missing_features:
            print(f"é”™è¯¯ï¼šæ•°æ®ç¼ºå°‘å¿…è¦ç‰¹å¾åˆ—: {', '.join(missing_features)}")
            return

        # 3. å¤„ç†ç‰¹å¾æ•°æ®
        X = df[required_features].copy()
        for col in required_features:
            X[col] = X[col].fillna(0)
        X = X.astype(float)

        # 4. ç‰¹å¾æ ‡å‡†åŒ–
        try:
            if os.path.exists(scaler_path):
                scaler = joblib.load(scaler_path)
                if len(scaler.feature_names_in_) != len(required_features):
                    raise ValueError(f"æ ‡å‡†åŒ–å™¨éœ€11ä¸ªç‰¹å¾ï¼Œå½“å‰ä»…{len(scaler.feature_names_in_)}ä¸ª")
                print(f"æˆåŠŸåŠ è½½æ ‡å‡†åŒ–å™¨: {scaler_path}ï¼ˆ11ä¸ªç‰¹å¾é€‚é…ï¼‰")
            else:
                raise FileNotFoundError("æ ‡å‡†åŒ–å™¨æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†åŸºäº11ä¸ªç‰¹å¾æ–°å»º")

            X_scaled = scaler.transform(X)
        except (FileNotFoundError, ValueError) as e:
            print(f"æç¤ºï¼š{e}ï¼Œè®­ç»ƒæ–°æ ‡å‡†åŒ–å™¨")
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
            joblib.dump(scaler, scaler_path)
            print(f"æ–°æ ‡å‡†åŒ–å™¨å·²ä¿å­˜åˆ°: {scaler_path}ï¼ˆ11ä¸ªç‰¹å¾ï¼‰")
        except Exception as e:
            print(f"æ ‡å‡†åŒ–è¿‡ç¨‹å‡ºé”™: {e}")
            return

        # 5. åŠ è½½äºŒåˆ†ç±»æ¨¡å‹
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"äºŒåˆ†ç±»æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")

        # å®ä¾‹åŒ–æ¨¡å‹æ—¶ä½¿ç”¨æ­£ç¡®çš„å‚æ•°ï¼ˆhidden_size=64, num_layers=1ï¼‰
        model = PeriodontalTransformerClassifier(
            input_size=11,
            hidden_size=64,  # ä¸æƒé‡æ–‡ä»¶ä¸€è‡´
            num_layers=1,  # ä¸æƒé‡æ–‡ä»¶ä¸€è‡´
            num_classes=2
        )

        # åŠ è½½æƒé‡æ—¶å¤„ç†ä¸åŒ¹é…çš„é”®
        state_dict = torch.load(model_path, weights_only=True)

        # è°ƒæ•´è¾“å‡ºå±‚æƒé‡çš„é”®å
        new_state_dict = {}
        for key, value in state_dict.items():
            if key == 'output_proj.2.weight':
                new_state_dict['output_proj.1.weight'] = value
            elif key == 'output_proj.2.bias':
                new_state_dict['output_proj.1.bias'] = value
            else:
                new_state_dict[key] = value

        # åŠ è½½è°ƒæ•´åçš„æƒé‡
        model.load_state_dict(new_state_dict)
        model.eval()
        print(f"æˆåŠŸåŠ è½½äºŒåˆ†ç±»Transformeræ¨¡å‹: {model_path}ï¼ˆè¾“å…¥11ç‰¹å¾ï¼Œè¾“å‡º2ç±»ï¼‰")

        # 6. é¢„æµ‹
        X_tensor = torch.tensor(X_scaled, dtype=torch.float32).unsqueeze(1)  # [batch, 1, 11]

        with torch.no_grad():
            outputs = model(X_tensor)
            _, y_pred = torch.max(outputs, dim=1)  # è¾“å‡º0æˆ–1
        y_pred = y_pred.numpy()

        # 7. ç»“æœæ˜ å°„ï¼ˆ0=è½»åº¦ï¼Œ1=é‡åº¦ï¼‰
        severity_mapping = {1: "è½»åº¦ç‰™å‘¨ç‚", 0: "é‡åº¦ç‰™å‘¨ç‚"}
        df['ç‰™å‘¨ç‚ä¸¥é‡ç¨‹åº¦ï¼ˆäºŒåˆ†ç±»ï¼‰'] = [severity_mapping.get(pred, "æœªçŸ¥") for pred in y_pred]
        df['é¢„æµ‹æ ‡ç­¾ï¼ˆ1=è½»åº¦,0=é‡åº¦ï¼‰'] = y_pred  # ä¿ç•™æ•°å­—æ ‡ç­¾

        # ä¿å­˜ç»“æœ
        prediction_file = file_path.replace('.xlsx', '_prediction_binary.xlsx')
        df.to_excel(prediction_file, index=False)
        print(f"\näºŒåˆ†ç±»é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: {prediction_file}")

        # 8. æ‰“å°è¯¦ç»†ç»“æœ
        print("\n=== ç‰™å‘¨ç‚ä¸¥é‡ç¨‹åº¦äºŒåˆ†ç±»é¢„æµ‹ç»“æœ ===")
        print(
            f"{'å§“å':<10} {'ç‰™å‘¨è¢‹æ·±åº¦(mm)':<15} {'CAL(mm)':<10} {'ç¼ºå¤±ç‰™æ•°':<10} {'é¢„æµ‹ç»“æœ'} {'é¢„æµ‹æ ‡ç­¾'}")
        print("-" * 120)

        for _, row in df.iterrows():
            print(
                f"{row['å§“å']:<10} {row['Periodontal pocket']:<15.1f} {row['CAL']:<10.1f} "
                f"{row['Missing teeth']:<10d} {row['ç‰™å‘¨ç‚ä¸¥é‡ç¨‹åº¦ï¼ˆäºŒåˆ†ç±»ï¼‰']:<12} {row['é¢„æµ‹æ ‡ç­¾ï¼ˆ0=è½»åº¦,1=é‡åº¦ï¼‰']}")

        # 9. ç»“æœç»Ÿè®¡
        severity_count = df['ç‰™å‘¨ç‚ä¸¥é‡ç¨‹åº¦ï¼ˆäºŒåˆ†ç±»ï¼‰'].value_counts()
        print("\n=== äºŒåˆ†ç±»é¢„æµ‹ç»“æœç»Ÿè®¡ ===")
        for severity, count in severity_count.items():
            percentage = (count / len(df)) * 100
            print(f"{severity}: {count}äººï¼ˆ{percentage:.1f}%ï¼‰")

    except FileNotFoundError as e:
        print(f"æ–‡ä»¶é”™è¯¯ï¼š{e}")
    except Exception as e:
        print(f"é¢„æµ‹è¿‡ç¨‹å‡ºé”™ï¼š{str(e)}")


class CTInferencePipeline:
    def __init__(self, nii_file_path, model_weight_path, patient_excel_path):
        """åˆå§‹åŒ–CTå½±åƒæ¨ç†æµæ°´çº¿"""
        self.nii_path = Path(nii_file_path)
        self.model_weight_path = Path(model_weight_path)
        self.patient_excel_path = Path(patient_excel_path)
        self.model = None
        self.nii_data = None
        self.inference_result = None
        self.class_probabilities = None
        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

    def load_nii_data(self):
        """è¯»å–å¹¶é¢„å¤„ç†niiæ–‡ä»¶æ•°æ®"""
        try:
            if not self.nii_path.exists():
                raise FileNotFoundError(f"niiæ–‡ä»¶ä¸å­˜åœ¨: {self.nii_path}")
            if self.nii_path.suffix not in ['.nii', '.nii.gz']:
                raise ValueError(f"æ–‡ä»¶ä¸æ˜¯niiæ ¼å¼: {self.nii_path.suffix}")

            nii_img = nib.load(str(self.nii_path))
            self.nii_data = nii_img.get_fdata()  # [H, W, D]
            # é¢„å¤„ç†ï¼šé€šé“å‰ç½®+æ‰¹æ¬¡ç»´åº¦
            self.nii_data = np.expand_dims(self.nii_data, axis=0)  # [1, H, W, D]
            self.nii_data = np.expand_dims(self.nii_data, axis=0)  # [1, 1, H, W, D]
            self.nii_data = torch.tensor(self.nii_data, dtype=torch.float32)

            print(f"âœ… æˆåŠŸè¯»å–niiæ–‡ä»¶: {self.nii_path.name}")
            print(f"ğŸ“Š æ•°æ®å½¢çŠ¶ï¼ˆbatch, channel, H, W, Dï¼‰: {self.nii_data.shape}")
            return True

        except Exception as e:
            print(f"âŒ è¯»å–niiæ–‡ä»¶å¤±è´¥: {str(e)}")
            return False

    def load_model(self):
        """åŠ è½½3D ResNet18æ¨¡å‹åŠæƒé‡"""
        try:
            if not self.model_weight_path.exists():
                raise FileNotFoundError(f"æ¨¡å‹æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {self.model_weight_path}")
            if self.model_weight_path.suffix != '.pth':
                raise ValueError(f"æƒé‡æ–‡ä»¶ä¸æ˜¯.pthæ ¼å¼: {self.model_weight_path.suffix}")

            self.model = resnet18_3d(num_classes=3, in_channels=1).to(self.device)
            # å¤„ç†å¤šGPUæƒé‡é”®åé—®é¢˜
            state_dict = torch.load(str(self.model_weight_path), map_location=self.device)
            model_state_dict = self.model.state_dict()
            new_state_dict = {}
            for k, v in state_dict.items():
                new_key = k[7:] if k.startswith('module.') else k
                if new_key in model_state_dict:
                    new_state_dict[new_key] = v
                else:
                    print(f"âš ï¸  è·³è¿‡ä¸åŒ¹é…çš„æƒé‡é”®: {k}")

            self.model.load_state_dict(new_state_dict, strict=False)
            self.model.eval()

            print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹æƒé‡: {self.model_weight_path.name}")
            print(f"ğŸ’» æ¨¡å‹è¿è¡Œè®¾å¤‡: {self.device}")
            return True

        except Exception as e:
            print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {str(e)}")
            return False

    def run_inference(self):
        """è¿è¡Œæ¨¡å‹æ¨ç†"""
        try:
            if self.nii_data is None:
                raise ValueError("è¯·å…ˆè°ƒç”¨load_nii_data()åŠ è½½æ•°æ®")
            if self.model is None:
                raise ValueError("è¯·å…ˆè°ƒç”¨load_model()åŠ è½½æ¨¡å‹")

            with torch.no_grad():
                input_data = self.nii_data.to(self.device)
                logits = self.model(input_data)
                self.class_probabilities = torch.softmax(logits, dim=1).cpu().numpy()[0]
                pred_class_code = np.argmax(self.class_probabilities) + 1  # 1/2/3ç¼–ç 
                self.inference_result = pred_class_code

            print(f"\n=== CTå½±åƒæ¨ç†ç»“æœ ===")
            print(f"ğŸ“ˆ ç±»åˆ«æ¦‚ç‡:")
            print(f"   - ç±»1 (less_than_1_3): {self.class_probabilities[0]:.4f}")
            print(f"   - ç±»2 (1_3_to_2_3):   {self.class_probabilities[1]:.4f}")
            print(f"   - ç±»3 (more_than_2_3): {self.class_probabilities[2]:.4f}")
            print(f"ğŸ† é¢„æµ‹ç±»åˆ«ç¼–ç : {self.inference_result}")
            return True

        except Exception as e:
            print(f"âŒ æ¨ç†å¤±è´¥: {str(e)}")
            return False

    def get_inference_code(self):
        """è·å–æ¨ç†ç»“æœ"""
        return self.inference_result


def run_ct_inference_pipeline():
    """è¿è¡ŒCTå½±åƒæ¨ç†æµæ°´çº¿å¹¶è¿”å›inference_code"""
    # é…ç½®å‚æ•°
    NII_FILE_PATH = "E:/D/data_set/raw_dataset/test/CT/volume-0.nii"
    MODEL_WEIGHT_PATH = "E:/D/è½¯ä»¶ç½‘ç«™æ¨¡å—/fenlei.pth"  # CTæ¨¡å‹æƒé‡è·¯å¾„
    PATIENT_EXCEL_PATH = "E:/D/è½¯ä»¶ç½‘ç«™æ¨¡å—/patient_periodontal_data.xlsx"  # æ‚£è€…Excelè·¯å¾„

    print("=== CTå½±åƒæ¨ç†æµæ°´çº¿å¯åŠ¨ ===")
    pipeline = CTInferencePipeline(
        nii_file_path=NII_FILE_PATH,
        model_weight_path=MODEL_WEIGHT_PATH,
        patient_excel_path=PATIENT_EXCEL_PATH
    )

    # æ­¥éª¤1ï¼šåŠ è½½niiæ•°æ®
    if not pipeline.load_nii_data():
        print("âŒ CTå½±åƒæ¨ç†ç»ˆæ­¢ï¼ˆæ•°æ®åŠ è½½å¤±è´¥ï¼‰")
        return None

    # æ­¥éª¤2ï¼šåŠ è½½æ¨¡å‹
    if not pipeline.load_model():
        print("âŒ CTå½±åƒæ¨ç†ç»ˆæ­¢ï¼ˆæ¨¡å‹åŠ è½½å¤±è´¥ï¼‰")
        return None

    # æ­¥éª¤3ï¼šè¿è¡Œæ¨ç†
    if not pipeline.run_inference():
        print("âŒ CTå½±åƒæ¨ç†ç»ˆæ­¢ï¼ˆæ¨ç†å¤±è´¥ï¼‰")
        return None

    return pipeline.get_inference_code()


if __name__ == "__main__":
    print("=== æ‚£è€…ç‰™å‘¨ç‚ä¸´åºŠæ•°æ®ï¼ˆ11ä¸ªç‰¹å¾ï¼‰å½•å…¥ä¸äºŒåˆ†ç±»é¢„æµ‹ç³»ç»Ÿ ===")
    while True:
        print("\nè¯·é€‰æ‹©æ“ä½œï¼š")
        print("1. å½•å…¥æ–°æ‚£è€…ç‰™å‘¨æ•°æ®ï¼ˆå«11ä¸ªç‰¹å¾ï¼‰")
        print("2. ä½¿ç”¨å·²æœ‰Excelæ•°æ®è¿›è¡ŒäºŒåˆ†ç±»é¢„æµ‹ï¼ˆ0=è½»åº¦ï¼Œ1=é‡åº¦ï¼‰")
        print("3. ä»…è¿è¡ŒCTå½±åƒæ¨ç†è·å–inference_code")
        print("4. é€€å‡º")
        choice = input("è¯·è¾“å…¥é€‰é¡¹ (1-4): ")

        if choice == '1':
            patients_data = collect_patient_data()
            save_to_excel(patients_data)
        elif choice == '2':
            load_and_predict()
        elif choice == '3':
            inference_code = run_ct_inference_pipeline()
            if inference_code is not None:
                print(f"CTå½±åƒæ¨ç†å®Œæˆï¼Œinference_code = {inference_code}")
        elif choice == '4':
            print("ç³»ç»Ÿå·²é€€å‡ºã€‚")
            break
        else:
            print("æ— æ•ˆé€‰é¡¹ï¼Œè¯·è¾“å…¥1-4ã€‚")