import pandas as pd
import os
import joblib
import torch
import numpy as np
import nibabel as nib
from sklearn.preprocessing import StandardScaler
from pathlib import Path
import warnings
from model2 import resnet18_3d  # ç¡®ä¿model.pyåœ¨ç›¸åŒç›®å½•æˆ–æ­£ç¡®è·¯å¾„

warnings.filterwarnings('ignore')

# ã€æ ¸å¿ƒä¿®æ­£ã€‘è¡¥å……ç¼ºå¤±çš„1ä¸ªç‰¹å¾ï¼ˆæ ¹æ®è®­ç»ƒæ¨¡å‹ï¼Œè¾“å…¥ç‰¹å¾æ•°ä¸º8ï¼Œå·²å°†"Missing_Feature"æ›¿æ¢ä¸º"inference_code"ï¼‰
COLUMN_ORDER = [
    'å§“å',
    'Periodontal pocket',  # 1. ç‰™å‘¨è¢‹æ·±åº¦
    'CAL',  # 2. ä¸´åºŠé™„ç€ä¸§å¤±
    'Missing teeth',  # 3. ç¼ºå¤±ç‰™æ•°
    'Occlusal',  # 4. å’¬åˆçŠ¶æ€
    'Looseness',  # 5. æœ€å¤§ç‰™é½¿æ¾åŠ¨åº¦
    'Root bifurcation lesion',  # 6. æœ€å¤§æ ¹åˆ†å‰ç—…å˜
    'Gingival condition',  # 7. ç‰™é¾ˆçŠ¶å†µ
    'inference_code'  # 8. ç¬¬8ä¸ªç‰¹å¾ï¼ˆå·²æ›¿æ¢ä¸ºinference_codeï¼‰
]


def collect_patient_data():
    """æ”¶é›†æ‚£è€…ç‰™å‘¨ç‚ä¸´åºŠæ•°æ®ï¼ˆå«inference_codeç‰¹å¾ï¼‰ï¼Œå¼ºåŒ–æŒ‡æ ‡éªŒè¯"""
    patients = []
    while True:
        patient_name = input("è¯·è¾“å…¥æ‚£è€…å§“åï¼ˆè¾“å…¥qé€€å‡ºï¼‰ï¼š")
        if patient_name.lower() == 'q':
            break

        # å§“åéç©ºéªŒè¯
        if not patient_name.strip():
            print("é”™è¯¯ï¼šæ‚£è€…å§“åä¸èƒ½ä¸ºç©ºï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")
            continue

        # 1. ç‰™å‘¨è¢‹æ·±åº¦ï¼ˆæ­£æ•°ï¼‰
        while True:
            pocket_input = input("è¯·è¾“å…¥æ‚£è€…ç‰™å‘¨è¢‹æ·±åº¦ï¼ˆå•ä½ï¼šmmï¼Œç›´æ¥è¾“å…¥æ•°å­—ï¼‰ï¼š")
            try:
                periodontal_pocket = float(pocket_input)
                if periodontal_pocket <= 0:
                    print("é”™è¯¯ï¼šç‰™å‘¨è¢‹æ·±åº¦å¿…é¡»ä¸ºæ­£æ•°ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")
                else:
                    break
            except ValueError:
                print("é”™è¯¯ï¼šç‰™å‘¨è¢‹æ·±åº¦å¿…é¡»æ˜¯æ•°å­—ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")

        # 2. CALï¼ˆéè´Ÿæ•°ï¼‰
        while True:
            cal_input = input("è¯·è¾“å…¥æ‚£è€…ä¸´åºŠé™„ç€ä¸§å¤±ï¼ˆCALï¼Œå•ä½ï¼šmmï¼Œç›´æ¥è¾“å…¥æ•°å­—ï¼‰ï¼š")
            try:
                cal = float(cal_input)
                if cal < 0:
                    print("é”™è¯¯ï¼šä¸´åºŠé™„ç€ä¸§å¤±ä¸èƒ½ä¸ºè´Ÿæ•°ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")
                else:
                    break
            except ValueError:
                print("é”™è¯¯ï¼šä¸´åºŠé™„ç€ä¸§å¤±å¿…é¡»æ˜¯æ•°å­—ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")

        # 3. ç¼ºå¤±ç‰™æ•°ï¼ˆéè´Ÿæ•´æ•°ï¼‰
        while True:
            missing_teeth_input = input("è¯·è¾“å…¥æ‚£è€…ç¼ºå¤±ç‰™æ•°ï¼ˆç›´æ¥è¾“å…¥æ•´æ•°ï¼‰ï¼š")
            try:
                missing_teeth = int(missing_teeth_input)
                if missing_teeth < 0:
                    print("é”™è¯¯ï¼šç¼ºå¤±ç‰™æ•°ä¸èƒ½ä¸ºè´Ÿæ•°ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")
                else:
                    break
            except ValueError:
                print("é”™è¯¯ï¼šç¼ºå¤±ç‰™æ•°å¿…é¡»æ˜¯æ•´æ•°ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")

        # 4. å’¬åˆçŠ¶æ€ï¼ˆ0/1/2ï¼‰
        while True:
            occlusal_input = input(
                "è¯·è¾“å…¥å’¬åˆçŠ¶æ€ï¼ˆ0=æ— å¼‚å¸¸ï¼Œ1=ç¼ºç‰™å°‘äº4é¢—ä¸”ç‰™é½¿æ´»åŠ¨åº¦ä½ï¼Œ2=ç¼ºç‰™è¶…è¿‡4é¢—ä¸”å…¨å£ç‰™é½¿é«˜åº¦æ¾åŠ¨ï¼‰ï¼š")
            if occlusal_input in ['0', '1', '2']:
                occlusal = int(occlusal_input)
                break
            print("é”™è¯¯ï¼šè¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥0ã€1æˆ–2ã€‚")

        # 5. æœ€å¤§ç‰™é½¿æ¾åŠ¨åº¦ï¼ˆ0-3ï¼‰
        while True:
            looseness_input = input("è¯·è¾“å…¥æœ€å¤§ç‰™é½¿æ¾åŠ¨åº¦ï¼ˆ0=Noneï¼Œ1=Grade 1ï¼Œ2=Grade 2ï¼Œ3=Grade 3ï¼‰ï¼š")
            if looseness_input in ['0', '1', '2', '3']:
                looseness = int(looseness_input)
                break
            print("é”™è¯¯ï¼šè¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥0-3ä¹‹é—´çš„æ•°å­—ã€‚")

        # 6. æœ€å¤§æ ¹åˆ†å‰ç—…å˜ï¼ˆ0-3ï¼‰
        while True:
            bifurcation_input = input("è¯·è¾“å…¥æœ€å¤§æ ¹åˆ†å‰ç—…å˜ï¼ˆ0=Noneï¼Œ1=Grade 1ï¼Œ2=Grade 2ï¼Œ3=Grade 3ï¼‰ï¼š")
            if bifurcation_input in ['0', '1', '2', '3']:
                root_bifurcation = int(bifurcation_input)
                break
            print("é”™è¯¯ï¼šè¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥0-3ä¹‹é—´çš„æ•°å­—ã€‚")

        # 7. ç‰™é¾ˆçŠ¶å†µï¼ˆ0-3ï¼‰
        while True:
            gingival_input = input(
                "è¯·è¾“å…¥ç‰™é¾ˆçŠ¶å†µï¼ˆ0=Noneï¼Œ1=å¶å°”å‡ºè¡€æ— æ˜æ˜¾ä¸é€‚ï¼Œ2=é¢‘ç¹å‡ºè¡€å¶æœ‰æº¢è„“ä¼´è½»åº¦æ¾åŠ¨ï¼Œ3=æŒç»­å‡ºè¡€æº¢è„“ä¼´å’€åš¼å›°éš¾ï¼‰ï¼š")
            if gingival_input in ['0', '1', '2', '3']:
                gingival_condition = int(gingival_input)
                break
            print("é”™è¯¯ï¼šè¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥0-3ä¹‹é—´çš„æ•°å­—ã€‚")

        # 8. inference_codeç‰¹å¾çš„è¾“å…¥ï¼ˆå¯¹åº”ç¬¬8ä¸ªç‰¹å¾ï¼‰
        while True:
            print("inference_codeæ¥æºï¼š")
            print("1. æ‰‹åŠ¨è¾“å…¥")
            print("2. é€šè¿‡CTå½±åƒè‡ªåŠ¨æ¨ç†è·å–")
            inference_choice = input("è¯·é€‰æ‹©inference_codeè·å–æ–¹å¼ (1æˆ–2): ")

            if inference_choice == '1':
                inference_code_input = input("è¯·è¾“å…¥inference_codeï¼ˆæ•°å­—ï¼‰ï¼š")
                try:
                    inference_code = float(inference_code_input)
                    if inference_code < 0:
                        print("é”™è¯¯ï¼šinference_codeä¸èƒ½ä¸ºè´Ÿæ•°ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")
                    else:
                        break
                except ValueError:
                    print("é”™è¯¯ï¼šinference_codeå¿…é¡»æ˜¯æ•°å­—ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")
            elif inference_choice == '2':
                inference_code = run_ct_inference_pipeline()
                if inference_code is not None:
                    print(f"CTå½±åƒæ¨ç†ç»“æœ: inference_code = {inference_code}")
                    break
                else:
                    print("CTå½±åƒæ¨ç†å¤±è´¥ï¼Œè¯·é€‰æ‹©å…¶ä»–æ–¹å¼æˆ–é‡è¯•ã€‚")
            else:
                print("é”™è¯¯ï¼šè¯·è¾“å…¥1æˆ–2é€‰æ‹©è·å–æ–¹å¼ã€‚")

        # æŒ‰8ä¸ªç‰¹å¾é¡ºåºç»„ç»‡æ•°æ®ï¼ˆä½¿ç”¨inference_codeä½œä¸ºç¬¬8ç‰¹å¾ï¼‰
        patients.append({
            'å§“å': patient_name,
            'Periodontal pocket': periodontal_pocket,
            'CAL': cal,
            'Missing teeth': missing_teeth,
            'Occlusal': occlusal,
            'Looseness': looseness,
            'Root bifurcation lesion': root_bifurcation,
            'Gingival condition': gingival_condition,
            'inference_code': inference_code  # ç¬¬8ä¸ªç‰¹å¾ï¼šinference_code
        })
        print(f"æ‚£è€… {patient_name} çš„ç‰™å‘¨æ•°æ®ï¼ˆå«8ä¸ªç‰¹å¾ï¼‰å·²è®°å½•ã€‚")

    return patients


def save_to_excel(patients, file_path="patient_periodontal_data.xlsx"):
    """ä¿å­˜å«8ä¸ªç‰¹å¾ï¼ˆå«inference_codeï¼‰çš„ç‰™å‘¨æ•°æ®åˆ°Excelï¼Œæ”¯æŒè¿½åŠ """
    if not patients:
        print("æ²¡æœ‰æ•°æ®å¯ä¿å­˜ã€‚")
        return

    df = pd.DataFrame(patients, columns=COLUMN_ORDER)

    if os.path.exists(file_path):
        try:
            existing_df = pd.read_excel(file_path)
            # ä¸ºæ—§æ•°æ®è¡¥å…¨ç¼ºå¤±çš„ç‰¹å¾åˆ—ï¼ˆå«inference_codeï¼‰
            for col in COLUMN_ORDER:
                if col not in existing_df.columns:
                    existing_df[col] = None
            existing_df = existing_df.reindex(columns=COLUMN_ORDER)
            combined_df = pd.concat([existing_df, df], ignore_index=True)
            combined_df.to_excel(file_path, index=False)
            print(f"æ•°æ®ï¼ˆå«8ä¸ªç‰¹å¾ï¼Œå«inference_codeï¼‰å·²è¿½åŠ åˆ° {file_path}")
        except Exception as e:
            print(f"è¿½åŠ æ•°æ®æ—¶å‡ºé”™: {e}")
    else:
        try:
            df.to_excel(file_path, index=False)
            print(f"æ–°æ–‡ä»¶å·²åˆ›å»º: {file_path}ï¼ˆå«8ä¸ªç‰™å‘¨ç‚ä¸´åºŠç‰¹å¾ï¼Œå«inference_codeï¼‰")
        except Exception as e:
            print(f"åˆ›å»ºæ–‡ä»¶æ—¶å‡ºé”™: {e}")


# ã€å…³é”®ä¿®å¤ã€‘å®šä¹‰ä¸è®­ç»ƒæ¨¡å‹å®Œå…¨åŒ¹é…çš„ç»´åº¦ï¼šinput_size=8ï¼Œhidden_size=128
class PeriodontalGRUClassifier(torch.nn.Module):
    def __init__(self, input_size=8, hidden_size=128, num_layers=4, num_classes=3):
        """
        100%åŒ¹é…è®­ç»ƒæ¨¡å‹çš„ç»“æ„ï¼š
        - input_size=8ï¼ˆè®­ç»ƒæ¨¡å‹ç”¨8ä¸ªç‰¹å¾ï¼Œå«inference_codeï¼‰
        - hidden_size=128ï¼ˆè®­ç»ƒæ¨¡å‹GRUéšè—å±‚ç»´åº¦ï¼‰
        - num_layers=4ï¼ˆ4å±‚GRUï¼ŒåŒ¹é…é”™è¯¯ä¿¡æ¯çš„l0-l3ï¼‰
        """
        super(PeriodontalGRUClassifier, self).__init__()
        self.gru = torch.nn.GRU(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,  # è¾“å…¥æ ¼å¼ï¼š[batch_size, seq_len, input_size]
            bidirectional=False  # ä»é”™è¯¯ä¿¡æ¯çœ‹ä¸ºå•å‘GRUï¼Œè‹¥è®­ç»ƒæ—¶åŒå‘éœ€æ”¹ä¸ºTrue
        )
        self.bn = torch.nn.BatchNorm1d(hidden_size)  # ç»´åº¦128ï¼ŒåŒ¹é…è®­ç»ƒæ¨¡å‹
        self.fc1 = torch.nn.Linear(hidden_size, hidden_size)  # è®­ç»ƒæ¨¡å‹fc1ä¸º128â†’128ï¼ˆé”™è¯¯ä¿¡æ¯ï¼š128,128ï¼‰
        self.fc2 = torch.nn.Linear(hidden_size, num_classes)  # 128â†’3ï¼ˆè¾“å‡º3ç±»ï¼‰
        self.relu = torch.nn.ReLU()  # è‹¥è®­ç»ƒæ—¶ç”¨å…¶ä»–æ¿€æ´»å‡½æ•°ï¼Œéœ€æ›¿æ¢

    def forward(self, x):
        """å‰å‘ä¼ æ’­ï¼šç»´åº¦å®Œå…¨åŒ¹é…è®­ç»ƒæ¨¡å‹"""
        # x: [batch_size, seq_len, 8] â†’ è¾“å…¥8ä¸ªç‰¹å¾ï¼ˆå«inference_codeï¼‰
        gru_out, _ = self.gru(x)  # è¾“å‡ºï¼š[batch_size, seq_len, 128]
        last_step_out = gru_out[:, -1, :]  # å–æœ€åæ—¶é—´æ­¥ï¼š[batch_size, 128]
        bn_out = self.bn(last_step_out)  # BatchNormï¼š[batch_size, 128]
        fc1_out = self.relu(self.fc1(bn_out))  # fc1ï¼š128â†’128
        final_out = self.fc2(fc1_out)  # fc2ï¼š128â†’3ï¼ˆè¾“å‡ºç±»åˆ«ï¼‰
        return final_out


def load_and_predict(file_path="patient_periodontal_data.xlsx",
                     model_path="E:/D/è½¯ä»¶ç½‘ç«™æ¨¡å—/fenji.pth",
                     scaler_path="periodontal_scaler.pkl"):
    """åŠ è½½8ä¸ªç‰¹å¾ï¼ˆå«inference_codeï¼‰çš„ç‰™å‘¨æ•°æ®ï¼Œç”¨åŒ¹é…ç»´åº¦çš„æ¨¡å‹é¢„æµ‹"""
    try:
        # 1. è¯»å–æ•°æ®å¹¶éªŒè¯8ä¸ªç‰¹å¾ï¼ˆå«inference_codeï¼‰
        df = pd.read_excel(file_path)
        print(f"æˆåŠŸåŠ è½½ {len(df)} æ¡æ‚£è€…ç‰™å‘¨æ•°æ®ï¼ˆå«8ä¸ªç‰¹å¾æ ¡éªŒï¼Œå«inference_codeï¼‰")

        # 2. æå–è®­ç»ƒæ¨¡å‹å¯¹åº”çš„8ä¸ªç‰¹å¾ï¼ˆå«inference_codeï¼Œä¸è®­ç»ƒæ—¶é¡ºåºä¸€è‡´ï¼‰
        required_features = [
            'Periodontal pocket', 'CAL', 'Missing teeth', 'Occlusal',
            'Looseness', 'Root bifurcation lesion', 'Gingival condition',
            'inference_code'  # ç¬¬8ä¸ªç‰¹å¾ï¼šinference_codeï¼ˆå·²æ›¿æ¢å®Œæˆï¼‰
        ]
        missing_features = [f for f in required_features if f not in df.columns]
        if missing_features:
            print(f"é”™è¯¯ï¼šæ•°æ®ç¼ºå°‘å¿…è¦ç‰¹å¾åˆ—: {', '.join(missing_features)}")
            return

        # 3. å¤„ç†ç‰¹å¾æ•°æ®ï¼ˆå¡«å……ç©ºå€¼ã€è½¬ä¸ºfloatï¼‰
        X = df[required_features].copy()
        # å¡«å……ç©ºå€¼ï¼ˆæ ¹æ®ç‰¹å¾å®é™…å«ä¹‰è°ƒæ•´ï¼Œæ­¤å¤„ç”¨0ç¤ºä¾‹ï¼‰
        for col in required_features:
            X[col] = X[col].fillna(0)
        X = X.astype(float)

        # 4. ç‰¹å¾æ ‡å‡†åŒ–ï¼ˆç¡®ä¿ä¸è®­ç»ƒæ¨¡å‹çš„æ ‡å‡†åŒ–å™¨ç»´åº¦ä¸€è‡´ï¼Œå«inference_codeï¼‰
        try:
            if os.path.exists(scaler_path):
                scaler = joblib.load(scaler_path)
                if len(scaler.feature_names_in_) != len(required_features):
                    raise ValueError(f"æ ‡å‡†åŒ–å™¨éœ€8ä¸ªç‰¹å¾ï¼ˆå«inference_codeï¼‰ï¼Œå½“å‰ä»…{len(scaler.feature_names_in_)}ä¸ª")
                print(f"æˆåŠŸåŠ è½½æ ‡å‡†åŒ–å™¨: {scaler_path}ï¼ˆ8ä¸ªç‰¹å¾é€‚é…ï¼Œå«inference_codeï¼‰")
            else:
                raise FileNotFoundError("æ ‡å‡†åŒ–å™¨æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†åŸºäº8ä¸ªç‰¹å¾ï¼ˆå«inference_codeï¼‰æ–°å»º")

            X_scaled = scaler.transform(X)
        except (FileNotFoundError, ValueError) as e:
            print(f"æç¤ºï¼š{e}ï¼Œè®­ç»ƒæ–°æ ‡å‡†åŒ–å™¨")
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
            joblib.dump(scaler, scaler_path)
            print(f"æ–°æ ‡å‡†åŒ–å™¨å·²ä¿å­˜åˆ°: {scaler_path}ï¼ˆ8ä¸ªç‰¹å¾ï¼Œå«inference_codeï¼‰")
        except Exception as e:
            print(f"æ ‡å‡†åŒ–è¿‡ç¨‹å‡ºé”™: {e}")
            return

        # 5. åŠ è½½åŒ¹é…ç»´åº¦çš„PyTorchæ¨¡å‹
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")

        # åˆå§‹åŒ–ä¸è®­ç»ƒæ¨¡å‹å®Œå…¨ä¸€è‡´çš„ç»“æ„ï¼ˆè¾“å…¥8ä¸ªç‰¹å¾ï¼Œå«inference_codeï¼‰
        model = PeriodontalGRUClassifier(
            input_size=8,  # 8ä¸ªç‰¹å¾ï¼ˆå«inference_codeï¼‰
            hidden_size=128,  # éšè—å±‚ç»´åº¦128
            num_layers=4,  # 4å±‚GRU
            num_classes=3  # 3åˆ†ç±»
        )
        # åŠ è½½æƒé‡ï¼ˆweights_only=Trueæ¶ˆé™¤è­¦å‘Šï¼‰
        model.load_state_dict(torch.load(model_path, weights_only=True))
        model.eval()  # è¯„ä¼°æ¨¡å¼
        print(f"æˆåŠŸåŠ è½½PyTorch GRUæ¨¡å‹: {model_path}ï¼ˆç»´åº¦å®Œå…¨åŒ¹é…ï¼Œå«inference_codeç‰¹å¾ï¼‰")

        # 6. é¢„æµ‹ï¼ˆé€‚é…GRUè¾“å…¥æ ¼å¼ï¼‰
        X_tensor = torch.tensor(X_scaled, dtype=torch.float32).unsqueeze(1)  # [batch, 1, 8]

        with torch.no_grad():
            outputs = model(X_tensor)
            _, y_pred = torch.max(outputs, dim=1)
        y_pred = y_pred.numpy()

        # 7. ç»“æœæ˜ å°„ä¸ä¿å­˜
        severity_mapping = {0: "è½»åº¦ç‰™å‘¨ç‚", 1: "ä¸­åº¦ç‰™å‘¨ç‚", 2: "é‡åº¦ç‰™å‘¨ç‚"}
        df['ç‰™å‘¨ç‚ä¸¥é‡ç¨‹åº¦'] = [severity_mapping.get(pred, "æœªçŸ¥") for pred in y_pred]

        prediction_file = file_path.replace('.xlsx', '_prediction.xlsx')
        df.to_excel(prediction_file, index=False)
        print(f"\né¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: {prediction_file}")

        # 8. æ‰“å°è¯¦ç»†ç»“æœï¼ˆå±•ç¤ºinference_codeç‰¹å¾ï¼‰
        print("\n=== ç‰™å‘¨ç‚ä¸¥é‡ç¨‹åº¦é¢„æµ‹ç»“æœ ===")
        print(
            f"{'å§“å':<10} {'ç‰™å‘¨è¢‹æ·±åº¦(mm)':<15} {'CAL(mm)':<10} {'ç¼ºå¤±ç‰™æ•°':<10} {'inference_code':<12} {'ç‰™é¾ˆçŠ¶å†µ':<20} {'é¢„æµ‹ç»“æœ'}")
        print("-" * 100)

        gingival_text_mapping = {
            0: "æ— å¼‚å¸¸",
            1: "å¶å°”å‡ºè¡€æ— ä¸é€‚",
            2: "é¢‘ç¹å‡ºè¡€å¶æº¢è„“",
            3: "æŒç»­å‡ºè¡€ä¼´å’€åš¼å›°éš¾"
        }

        for _, row in df.iterrows():
            print(
                f"{row['å§“å']:<10} {row['Periodontal pocket']:<15.1f} {row['CAL']:<10.1f} "
                f"{row['Missing teeth']:<10d} {row['inference_code']:<12.1f} "  # å±•ç¤ºinference_codeç‰¹å¾å€¼
                f"{gingival_text_mapping.get(row['Gingival condition'], 'æœªçŸ¥'):<20} "
                f"{row['ç‰™å‘¨ç‚ä¸¥é‡ç¨‹åº¦']}"
            )

        # 9. ç»“æœç»Ÿè®¡
        severity_count = df['ç‰™å‘¨ç‚ä¸¥é‡ç¨‹åº¦'].value_counts()
        print("\n=== é¢„æµ‹ç»“æœç»Ÿè®¡ ===")
        for severity, count in severity_count.items():
            percentage = (count / len(df)) * 100
            print(f"{severity}: {count}äººï¼ˆ{percentage:.1f}%ï¼‰")

    except FileNotFoundError as e:
        print(f"æ–‡ä»¶é”™è¯¯ï¼š{e}")
    except Exception as e:
        print(f"é¢„æµ‹è¿‡ç¨‹å‡ºé”™ï¼š{str(e)}")


class CTInferencePipeline:
    def __init__(self, nii_file_path, model_weight_path, patient_excel_path):
        """
        åˆå§‹åŒ–CTå½±åƒæ¨ç†æµæ°´çº¿
        :param nii_file_path: niiæ–‡ä»¶è·¯å¾„
        :param model_weight_path: æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„
        :param patient_excel_path: æ‚£è€…æ•°æ®Excelè·¯å¾„
        """
        self.nii_path = Path(nii_file_path)
        self.model_weight_path = Path(model_weight_path)
        self.patient_excel_path = Path(patient_excel_path)
        self.model = None
        self.nii_data = None
        self.inference_result = None
        self.class_probabilities = None
        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

    def load_nii_data(self):
        """è¯»å–å¹¶é¢„å¤„ç†niiæ–‡ä»¶æ•°æ®"""
        try:
            if not self.nii_path.exists():
                raise FileNotFoundError(f"niiæ–‡ä»¶ä¸å­˜åœ¨: {self.nii_path}")
            if self.nii_path.suffix not in ['.nii', '.nii.gz']:
                raise ValueError(f"æ–‡ä»¶ä¸æ˜¯niiæ ¼å¼: {self.nii_path.suffix}")

            nii_img = nib.load(str(self.nii_path))
            self.nii_data = nii_img.get_fdata()  # [H, W, D]
            # é¢„å¤„ç†ï¼šé€šé“å‰ç½®+æ‰¹æ¬¡ç»´åº¦
            self.nii_data = np.expand_dims(self.nii_data, axis=0)  # [1, H, W, D]
            self.nii_data = np.expand_dims(self.nii_data, axis=0)  # [1, 1, H, W, D]
            self.nii_data = torch.tensor(self.nii_data, dtype=torch.float32)

            print(f"âœ… æˆåŠŸè¯»å–niiæ–‡ä»¶: {self.nii_path.name}")
            print(f"ğŸ“Š æ•°æ®å½¢çŠ¶ï¼ˆbatch, channel, H, W, Dï¼‰: {self.nii_data.shape}")
            return True

        except Exception as e:
            print(f"âŒ è¯»å–niiæ–‡ä»¶å¤±è´¥: {str(e)}")
            return False

    def load_model(self):
        """åŠ è½½3D ResNet18æ¨¡å‹åŠæƒé‡"""
        try:
            if not self.model_weight_path.exists():
                raise FileNotFoundError(f"æ¨¡å‹æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {self.model_weight_path}")
            if self.model_weight_path.suffix != '.pth':
                raise ValueError(f"æƒé‡æ–‡ä»¶ä¸æ˜¯.pthæ ¼å¼: {self.model_weight_path.suffix}")

            self.model = resnet18_3d(num_classes=3, in_channels=1).to(self.device)
            # å¤„ç†å¤šGPUæƒé‡é”®åé—®é¢˜
            state_dict = torch.load(str(self.model_weight_path), map_location=self.device)
            model_state_dict = self.model.state_dict()
            new_state_dict = {}
            for k, v in state_dict.items():
                new_key = k[7:] if k.startswith('module.') else k
                if new_key in model_state_dict:
                    new_state_dict[new_key] = v
                else:
                    print(f"âš ï¸  è·³è¿‡ä¸åŒ¹é…çš„æƒé‡é”®: {k}")

            self.model.load_state_dict(new_state_dict, strict=False)
            self.model.eval()

            print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹æƒé‡: {self.model_weight_path.name}")
            print(f"ğŸ’» æ¨¡å‹è¿è¡Œè®¾å¤‡: {self.device}")
            return True

        except Exception as e:
            print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {str(e)}")
            return False

    def run_inference(self):
        """è¿è¡Œæ¨¡å‹æ¨ç†"""
        try:
            if self.nii_data is None:
                raise ValueError("è¯·å…ˆè°ƒç”¨load_nii_data()åŠ è½½æ•°æ®")
            if self.model is None:
                raise ValueError("è¯·å…ˆè°ƒç”¨load_model()åŠ è½½æ¨¡å‹")

            with torch.no_grad():
                input_data = self.nii_data.to(self.device)
                logits = self.model(input_data)
                self.class_probabilities = torch.softmax(logits, dim=1).cpu().numpy()[0]
                pred_class_code = np.argmax(self.class_probabilities) + 1  # 1/2/3ç¼–ç 
                self.inference_result = pred_class_code

            print(f"\n=== CTå½±åƒæ¨ç†ç»“æœ ===")
            print(f"ğŸ“ˆ ç±»åˆ«æ¦‚ç‡:")
            print(f"   - ç±»1 (less_than_1_3): {self.class_probabilities[0]:.4f}")
            print(f"   - ç±»2 (1_3_to_2_3):   {self.class_probabilities[1]:.4f}")
            print(f"   - ç±»3 (more_than_2_3): {self.class_probabilities[2]:.4f}")
            print(f"ğŸ† é¢„æµ‹ç±»åˆ«ç¼–ç : {self.inference_result}")
            return True

        except Exception as e:
            print(f"âŒ æ¨ç†å¤±è´¥: {str(e)}")
            return False

    def get_inference_code(self):
        """è·å–æ¨ç†ç»“æœ"""
        return self.inference_result


def run_ct_inference_pipeline():
    """è¿è¡ŒCTå½±åƒæ¨ç†æµæ°´çº¿å¹¶è¿”å›inference_code"""
    # é…ç½®å‚æ•°
    NII_FILE_PATH = "E:/D/data_set/raw_dataset/test/CT/volume-0.nii"
    MODEL_WEIGHT_PATH = "E:/D/è½¯ä»¶ç½‘ç«™æ¨¡å—/fenlei.pth"  # CTæ¨¡å‹æƒé‡è·¯å¾„
    PATIENT_EXCEL_PATH = "E:/D/è½¯ä»¶ç½‘ç«™æ¨¡å—/patient_periodontal_data.xlsx"  # æ‚£è€…Excelè·¯å¾„

    print("=== CTå½±åƒæ¨ç†æµæ°´çº¿å¯åŠ¨ ===")
    pipeline = CTInferencePipeline(
        nii_file_path=NII_FILE_PATH,
        model_weight_path=MODEL_WEIGHT_PATH,
        patient_excel_path=PATIENT_EXCEL_PATH
    )

    # æ­¥éª¤1ï¼šåŠ è½½niiæ•°æ®
    if not pipeline.load_nii_data():
        print("âŒ CTå½±åƒæ¨ç†ç»ˆæ­¢ï¼ˆæ•°æ®åŠ è½½å¤±è´¥ï¼‰")
        return None

    # æ­¥éª¤2ï¼šåŠ è½½æ¨¡å‹
    if not pipeline.load_model():
        print("âŒ CTå½±åƒæ¨ç†ç»ˆæ­¢ï¼ˆæ¨¡å‹åŠ è½½å¤±è´¥ï¼‰")
        return None

    # æ­¥éª¤3ï¼šè¿è¡Œæ¨ç†
    if not pipeline.run_inference():
        print("âŒ CTå½±åƒæ¨ç†ç»ˆæ­¢ï¼ˆæ¨ç†å¤±è´¥ï¼‰")
        return None

    return pipeline.get_inference_code()


if __name__ == "__main__":
    print("=== æ‚£è€…ç‰™å‘¨ç‚ä¸´åºŠæ•°æ®ï¼ˆ8ä¸ªç‰¹å¾ï¼Œå«inference_codeï¼‰å½•å…¥ä¸ä¸¥é‡ç¨‹åº¦é¢„æµ‹ç³»ç»Ÿ ===")
    while True:
        print("\nè¯·é€‰æ‹©æ“ä½œï¼š")
        print("1. å½•å…¥æ–°æ‚£è€…ç‰™å‘¨æ•°æ®ï¼ˆå«8ä¸ªç‰¹å¾ï¼Œå«inference_codeï¼‰")
        print("2. ä½¿ç”¨å·²æœ‰Excelæ•°æ®é¢„æµ‹ç‰™å‘¨ç‚ä¸¥é‡ç¨‹åº¦")
        print("3. ä»…è¿è¡ŒCTå½±åƒæ¨ç†è·å–inference_code")
        print("4. é€€å‡º")
        choice = input("è¯·è¾“å…¥é€‰é¡¹ (1-4): ")

        if choice == '1':
            patients_data = collect_patient_data()
            save_to_excel(patients_data)
        elif choice == '2':
            load_and_predict()
        elif choice == '3':
            inference_code = run_ct_inference_pipeline()
            if inference_code is not None:
                print(f"CTå½±åƒæ¨ç†å®Œæˆï¼Œinference_code = {inference_code}")
        elif choice == '4':
            print("ç³»ç»Ÿå·²é€€å‡ºã€‚")
            break
        else:
            print("æ— æ•ˆé€‰é¡¹ï¼Œè¯·è¾“å…¥1-4ã€‚")