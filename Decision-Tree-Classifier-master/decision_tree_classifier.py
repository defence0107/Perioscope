import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.metrics import (accuracy_score, roc_auc_score, precision_score,
                             recall_score, f1_score, confusion_matrix, roc_curve,
                             precision_recall_curve, average_precision_score, r2_score)
from sklearn.calibration import calibration_curve
import joblib
import os
import shap
from scipy.stats import bootstrap  # ç”¨äºè®¡ç®—ç½®ä¿¡åŒºé—´
from openpyxl import Workbook
from openpyxl.utils.dataframe import dataframe_to_rows
# è®¾ç½®ä¸­æ–‡å­—ä½“ï¼Œç¡®ä¿ä¸­æ–‡æ­£å¸¸æ˜¾ç¤º
plt.rcParams["font.family"] = ["Arial", "sans-serif"]
plt.rcParams["axes.unicode_minus"] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜

# æ–‡ä»¶è·¯å¾„
file_path = 'E:/D/linjun.xlsx'

# æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥
if os.path.exists(file_path):
    print("æ–‡ä»¶å­˜åœ¨")
    datasets = pd.read_excel(file_path, header=0)
else:
    print("æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥è·¯å¾„å’Œæ–‡ä»¶å")
    exit()

# æ•°æ®é¢„å¤„ç†
Y = datasets.iloc[:, 0]
X = datasets.iloc[:, 1:]
feature_names = X.columns.tolist()

# åˆ’åˆ†æ•°æ®é›†ï¼šè®­ç»ƒé›†70%ï¼ŒéªŒè¯é›†15%ï¼Œæµ‹è¯•é›†15%
X_temp, X_Test, Y_temp, Y_Test = train_test_split(X, Y, test_size=0.15, random_state=0)
X_Train, X_Val, Y_Train, Y_Val = train_test_split(X_temp, Y_temp, test_size=(0.15 / 0.85), random_state=0)

# ç‰¹å¾æ ‡å‡†åŒ–
sc_X = StandardScaler()
X_Train = pd.DataFrame(sc_X.fit_transform(X_Train), columns=feature_names)
X_Val = pd.DataFrame(sc_X.transform(X_Val), columns=feature_names)
X_Test = pd.DataFrame(sc_X.transform(X_Test), columns=feature_names)


def calculate_metrics(y_true, y_pred, y_proba, set_name=""):
    """è®¡ç®—å¹¶è¿”å›æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡"""
    cm = confusion_matrix(y_true, y_pred)
    tn, fp, fn, tp = cm.ravel()

    metrics = {
        "Accuracy": accuracy_score(y_true, y_pred),
        "AUC": roc_auc_score(y_true, y_proba),
        "Precision": precision_score(y_true, y_pred),
        "Recall": recall_score(y_true, y_pred),
        "F1": f1_score(y_true, y_pred),
        "Specificity": tn / (tn + fp)
    }

    # æ‰“å°æŒ‡æ ‡
    print(f"{set_name}æŒ‡æ ‡:")
    for metric, value in metrics.items():
        print(f"  {metric}: {value:.4f}")

    return metrics


# å®éªŒä¸åŒæ ‘æ•°é‡çš„å½±å“
n_estimators_list = range(1, 101, 1)

# åˆ›å»ºDataFrameä¿å­˜æ‰€æœ‰æŒ‡æ ‡
results_df = pd.DataFrame(columns=['n_estimators',
                                   'Train_Accuracy', 'Train_AUC', 'Train_Precision', 'Train_Recall', 'Train_F1',
                                   'Train_Specificity',
                                   'Val_Accuracy', 'Val_AUC', 'Val_Precision', 'Val_Recall', 'Val_F1',
                                   'Val_Specificity',
                                   'Test_Accuracy', 'Test_AUC', 'Test_Precision', 'Test_Recall', 'Test_F1',
                                   'Test_Specificity'])

for n_est in n_estimators_list:
    print(f"\næ­£åœ¨è®­ç»ƒ n_estimators = {n_est}...")

    # åˆå§‹åŒ–åˆ†ç±»å™¨
    rf_classifier = RandomForestClassifier(
        n_estimators=n_est,
        criterion='entropy',
        random_state=0,
        max_depth=10,
        min_samples_leaf=10,
        n_jobs=-1,
        class_weight='balanced'
    )

    # è®­ç»ƒæ¨¡å‹
    rf_classifier.fit(X_Train, Y_Train)

    # è®­ç»ƒé›†é¢„æµ‹
    Y_Train_Pred = rf_classifier.predict(X_Train)
    y_train_proba = rf_classifier.predict_proba(X_Train)[:, 1]

    # éªŒè¯é›†é¢„æµ‹
    Y_Val_Pred = rf_classifier.predict(X_Val)
    y_val_proba = rf_classifier.predict_proba(X_Val)[:, 1]

    # æµ‹è¯•é›†é¢„æµ‹
    Y_Test_Pred = rf_classifier.predict(X_Test)
    y_test_proba = rf_classifier.predict_proba(X_Test)[:, 1]

    # è®¡ç®—æŒ‡æ ‡
    train_metrics = calculate_metrics(Y_Train, Y_Train_Pred, y_train_proba, "è®­ç»ƒé›†")
    val_metrics = calculate_metrics(Y_Val, Y_Val_Pred, y_val_proba, "éªŒè¯é›†")
    test_metrics = calculate_metrics(Y_Test, Y_Test_Pred, y_test_proba, "æµ‹è¯•é›†")

    # å°†ç»“æœæ·»åŠ åˆ°DataFrame
    results_df.loc[len(results_df)] = {
        'n_estimators': n_est,
        'Train_Accuracy': train_metrics['Accuracy'],
        'Train_AUC': train_metrics['AUC'],
        'Train_Precision': train_metrics['Precision'],
        'Train_Recall': train_metrics['Recall'],
        'Train_F1': train_metrics['F1'],
        'Train_Specificity': train_metrics['Specificity'],
        'Val_Accuracy': val_metrics['Accuracy'],
        'Val_AUC': val_metrics['AUC'],
        'Val_Precision': val_metrics['Precision'],
        'Val_Recall': val_metrics['Recall'],
        'Val_F1': val_metrics['F1'],
        'Val_Specificity': val_metrics['Specificity'],
        'Test_Accuracy': test_metrics['Accuracy'],
        'Test_AUC': test_metrics['AUC'],
        'Test_Precision': test_metrics['Precision'],
        'Test_Recall': test_metrics['Recall'],
        'Test_F1': test_metrics['F1'],
        'Test_Specificity': test_metrics['Specificity']
    }

    # æ‰“å°å½“å‰è¿›åº¦
    print(f"å½“å‰è¿›åº¦ ({n_est}/100)")
    print("-" * 50)

# ä¿å­˜ç»“æœåˆ°Excelæ–‡ä»¶
output_file = "random_forest_metrics.xlsx"

# å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤
if os.path.exists(output_file):
    os.remove(output_file)

# åˆ›å»ºæ–°çš„Excelæ–‡ä»¶
wb = Workbook()
ws = wb.active

# å°†DataFrameå†™å…¥Excel
for r in dataframe_to_rows(results_df, index=False, header=True):
    ws.append(r)

# ä¿å­˜Excelæ–‡ä»¶
wb.save(output_file)
print(f"\næ‰€æœ‰æŒ‡æ ‡å·²ä¿å­˜åˆ° {output_file}")

# å¯è§†åŒ–æŒ‡æ ‡å˜åŒ–
plt.figure(figsize=(14, 8))
metrics_to_plot = ['Accuracy', 'AUC', 'F1']
colors = ['#1f77b4', '#ff7f0e', '#2ca02c']

for idx, metric in enumerate(metrics_to_plot):
    plt.plot(results_df['n_estimators'], results_df[f'Train_{metric}'],
             color=colors[idx], linestyle='--', label=f'Train {metric}')
    plt.plot(results_df['n_estimators'], results_df[f'Val_{metric}'],
             color=colors[idx], linestyle=':', label=f'Val {metric}')
    plt.plot(results_df['n_estimators'], results_df[f'Test_{metric}'],
             color=colors[idx], linewidth=2, label=f'Test {metric}')

plt.title('æ¨¡å‹æ€§èƒ½éšæ ‘æ•°é‡å˜åŒ–')
plt.xlabel('æ ‘çš„æ•°é‡')
plt.ylabel('åˆ†æ•°')
plt.xticks(n_estimators_list)
plt.grid(True, alpha=0.3)
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.savefig('model_performance_plot.png')
plt.show()

# ä¿å­˜æœ€ç»ˆæ¨¡å‹ï¼ˆå‡è®¾n_estimators=100ä¸ºæœ€ä½³æ¨¡å‹ï¼‰
final_model = rf_classifier
joblib.dump(final_model, 'random_forest_model_final.pkl', compress=True)


# ==================== ç»˜åˆ¶æ··æ·†çŸ©é˜µ ====================
import os
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix


def plot_confusion_matrix(y_true, y_pred, set_name="", output_dir="confusion_matrices"):
    """ç»˜åˆ¶å¹¶ä¿å­˜æ··æ·†çŸ©é˜µï¼Œä½¿ç”¨Arialå­—ä½“"""
    os.makedirs(output_dir, exist_ok=True)

    # è®¾ç½®å…¨å±€å­—ä½“ä¸ºArial
    plt.rcParams["font.family"] = ["Arial", "sans-serif"]

    cm = confusion_matrix(y_true, y_pred)

    plt.figure(figsize=(10, 8))
    # è·å–heatmapçš„è½´å¯¹è±¡
    ax = sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                     xticklabels=['0', '1'],
                     yticklabels=['0', '1'],
                     annot_kws={"size": 25})

    # è®¾ç½®æ ‡é¢˜å’Œæ ‡ç­¾
    plt.title(f'Confusion Matrix({set_name})', fontsize=25)
    plt.xlabel('Predicted Label', fontsize=25)
    plt.ylabel('True Label', fontsize=25)

    # ä½¿ç”¨è½´å¯¹è±¡çš„tick_paramsæ–¹æ³•è®¾ç½®åˆ»åº¦
    ax.tick_params(axis='x', labelsize=25)  # xè½´åˆ»åº¦
    ax.tick_params(axis='y', labelsize=22)  # yè½´åˆ»åº¦

    plt.tight_layout()
    plt.savefig(f"{output_dir}/confusion_matrix_{set_name.lower()}.png", dpi=300)
    plt.close()


# ç»˜åˆ¶æ‰€æœ‰æ··æ·†çŸ©é˜µ
plot_confusion_matrix(Y_Train, final_model.predict(X_Train), "Training")
plot_confusion_matrix(Y_Val, final_model.predict(X_Val), "Validation")
plot_confusion_matrix(Y_Test, final_model.predict(X_Test), "Test")

# ==================== ç»˜åˆ¶ROCæ›²çº¿ ====================
def plot_roc_curves(y_true_list, y_proba_list, set_names, output_path="roc_curves.png"):
    """
    ç»˜åˆ¶å¤šç»„æ•°æ®çš„ROCæ›²çº¿

    Parameters:
    y_true_list (list): çœŸå®æ ‡ç­¾åˆ—è¡¨ï¼ˆæ¯ä¸ªå…ƒç´ ä¸ºnumpyæ•°ç»„ï¼‰
    y_proba_list (list): é¢„æµ‹æ¦‚ç‡åˆ—è¡¨ï¼ˆæ¯ä¸ªå…ƒç´ ä¸ºnumpyæ•°ç»„ï¼Œæ­£ç±»æ¦‚ç‡ï¼‰
    set_names (list): æ•°æ®é›†åç§°åˆ—è¡¨ï¼ˆå¦‚['Train', 'Val', 'Test']ï¼‰
    output_path (str): å›¾åƒä¿å­˜è·¯å¾„
    """
    plt.figure(figsize=(10, 8))

    # å®šä¹‰é¢œè‰²å’Œæ ·å¼
    colors = {
        'Train': {'color': '#88C4D7', 'marker': 'o', 'ls': '-'},
        'Validation': {'color': '#D0EAD5', 'marker': 's', 'ls': '--'},
        'Test': {'color': '#AFADD2', 'marker': '^', 'ls': ':'}
    }

    for y_true, y_proba, name in zip(y_true_list, y_proba_list, set_names):
        fpr, tpr, _ = roc_curve(y_true, y_proba)
        roc_auc = roc_auc_score(y_true, y_proba)

        # ä½¿ç”¨æŒ‡å®šçš„é¢œè‰²å’Œæ ·å¼
        style = colors.get(name, {'color': 'gray', 'ls': '-'})
        plt.plot(fpr, tpr, lw=6, label=f'{name} (AUC = {roc_auc:.4f})',
                 color=style['color'], linestyle=style['ls'])
        plt.plot([0, 1], [0, 1], color='gray', lw=3, linestyle='--')  # å¯¹è§’çº¿

    plt.xlim([-0.05, 1.05])
    plt.ylim([-0.05, 1.05])
    # å¢å¤§åæ ‡è½´æ ‡ç­¾å’Œåˆ»åº¦å­—ä½“å¤§å°
    plt.xlabel('False Positive Rate (FPR)', fontsize=20, fontname='Arial')
    plt.ylabel('True Positive Rate (TPR)', fontsize=20, fontname='Arial')
    plt.xticks(fontsize=20)  # å¢å¤§xè½´åˆ»åº¦
    plt.yticks(fontsize=20)  # å¢å¤§yè½´åˆ»åº¦
    plt.title('ROC Curve', fontsize=20, fontname='Arial')

    # è°ƒæ•´å›¾ä¾‹ä½ç½®ï¼Œå‘ä¸Šç§»åŠ¨ï¼ˆé€šè¿‡bbox_to_anchorå¾®è°ƒï¼‰
    # bbox_to_anchorçš„å‰ä¸¤ä¸ªå€¼æ˜¯ç›¸å¯¹åæ ‡ï¼Œ(1, 0.1)è¡¨ç¤ºå³ä¾§10%é«˜åº¦ä½ç½®
    plt.legend(loc='lower right', bbox_to_anchor=(1, 0.005),
               fontsize=20, markerscale=1.5, frameon=False)

    # æ·»åŠ ç°è‰²åŠé€æ˜ç½‘æ ¼çº¿
    plt.grid(True, color='gray', alpha=0.3)

    # å»é™¤ä¸Šè½´å’Œå³ä¾§è½´
    ax = plt.gca()
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)

    plt.tight_layout()
    plt.savefig(output_path, dpi=600)
    plt.close()
    print(f"ROC curve saved to {output_path}")


# ç”ŸæˆROCæ›²çº¿æ•°æ®
y_train_proba_final = final_model.predict_proba(X_Train)[:, 1]
y_val_proba_final = final_model.predict_proba(X_Val)[:, 1]
y_test_proba_final = final_model.predict_proba(X_Test)[:, 1]

# å‡†å¤‡æ•°æ®
y_true_list = [Y_Train, Y_Val, Y_Test]
y_proba_list = [y_train_proba_final, y_val_proba_final, y_test_proba_final]
set_names = ['Train', 'Validation', 'Test']

# è°ƒç”¨å‡½æ•°ç»˜åˆ¶ROCæ›²çº¿
plot_roc_curves(y_true_list, y_proba_list, set_names, output_path="roc_curves.png")


# ==================== ç»˜åˆ¶PRæ›²çº¿ ====================
def plot_pr_curves(y_true_list, y_proba_list, set_names, output_path="pr_curves.png"):
    """ç»˜åˆ¶å¤šç»„æ•°æ®çš„PRæ›²çº¿"""
    plt.figure(figsize=(10, 8))

    # å®šä¹‰é¢œè‰²å’Œæ ·å¼
    colors = {
        'Train': {'color': '#88C4D7', 'marker': 'o', 'ls': '-'},
        'Validation': {'color': '#D0EAD5', 'marker': 's', 'ls': '--'},
        'Test': {'color': '#AFADD2', 'marker': '^', 'ls': ':'}
    }

    for y_true, y_proba, name in zip(y_true_list, y_proba_list, set_names):
        precision, recall, _ = precision_recall_curve(y_true, y_proba)
        avg_precision = average_precision_score(y_true, y_proba)

        # ä½¿ç”¨æŒ‡å®šçš„é¢œè‰²å’Œæ ·å¼
        style = colors.get(name, {'color': 'gray', 'ls': '-'})
        plt.plot(recall, precision, lw=6,
                 label=f'{name} (AP = {avg_precision:.4f})',
                 color=style['color'], linestyle=style['ls'])

    plt.xlim([-0.05, 1.05])
    plt.ylim([-0.05, 1.05])
    # å¢å¤§åæ ‡è½´æ ‡ç­¾å’Œåˆ»åº¦å­—ä½“å¤§å°
    plt.xlabel('Recall', fontsize=20, fontname='Arial')
    plt.ylabel('Precision', fontsize=20, fontname='Arial')
    plt.xticks(fontsize=20)  # å¢å¤§xè½´åˆ»åº¦
    plt.yticks(fontsize=20)  # å¢å¤§yè½´åˆ»åº¦
    plt.title('Precision-Recall Curve', fontsize=20, fontname='Arial')
    # å¢å¤§å›¾ä¾‹ç¬¦å·å¹¶è®¾ç½®å­—ä½“å¤§å°ï¼Œå–æ¶ˆè¾¹æ¡†
    plt.legend(loc='lower left', fontsize=20, markerscale=1.5, frameon=False)

    # æ·»åŠ ç°è‰²åŠé€æ˜ç½‘æ ¼çº¿
    plt.grid(True, color='gray', alpha=0.3)

    # å»é™¤ä¸Šè½´å’Œå³ä¾§è½´
    ax = plt.gca()
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)

    plt.tight_layout()
    plt.savefig(output_path, dpi=600)
    plt.close()
    print(f"PR curve saved to {output_path}")


# è°ƒç”¨å‡½æ•°ç»˜åˆ¶PRæ›²çº¿
plot_pr_curves(y_true_list, y_proba_list, set_names, output_path="pr_curves.png")


# ==================== ç»˜åˆ¶æ ¡å‡†æ›²çº¿ ====================
def plot_calibration_curves(y_true_list, y_proba_list, set_names, output_path="calibration_curves.png"):
    """ç»˜åˆ¶å¤šç»„æ•°æ®çš„æ ¡å‡†æ›²çº¿ï¼ˆæ— æ›²çº¿ç¬¦å·å’Œå›¾ä¾‹ç¬¦å·ï¼‰"""
    plt.figure(figsize=(10, 8))

    # å®šä¹‰é¢œè‰²å’Œæ ·å¼ï¼ˆç§»é™¤äº†markerå‚æ•°ï¼‰
    colors = {
        'Train': {'color': '#88C4D7', 'ls': '-'},
        'Validation': {'color': '#D0EAD5', 'ls': '--'},
        'Test': {'color': '#AFADD2', 'ls': ':'}
    }

    # ç»˜åˆ¶ç†æƒ³æ ¡å‡†çº¿
    plt.plot([0, 1], [0, 1], linestyle='--', label='Perfectly calibrated',
             color='gray', lw=3)

    for y_true, y_proba, name in zip(y_true_list, y_proba_list, set_names):
        prob_true, prob_pred = calibration_curve(y_true, y_proba, n_bins=12)

        # ä½¿ç”¨æŒ‡å®šçš„é¢œè‰²å’Œæ ·å¼ï¼ˆä¸è®¾ç½®markerï¼‰
        style = colors.get(name, {'color': 'gray', 'ls': '-'})
        plt.plot(prob_pred, prob_true, linestyle=style['ls'],  # ç§»é™¤äº†markerå‚æ•°
                 label=f'{name}', color=style['color'], lw=6)  # ç§»é™¤äº†markersize

    # å¢å¤§åæ ‡è½´æ ‡ç­¾å’Œåˆ»åº¦å­—ä½“å¤§å°
    plt.xlabel('Mean predicted probability', fontsize=20, fontname='Arial')
    plt.ylabel('Fraction of positives', fontsize=20, fontname='Arial')
    plt.xticks(fontsize=20)  # å¢å¤§xè½´åˆ»åº¦
    plt.yticks(fontsize=20)  # å¢å¤§yè½´åˆ»åº¦
    plt.title('Calibration Curve', fontsize=20, fontname='Arial')
    # å¢å¤§å›¾ä¾‹å­—ä½“å¤§å°ï¼Œå–æ¶ˆè¾¹æ¡†å’Œæ ‡è®°ç¼©æ”¾
    plt.legend(loc='upper left', fontsize=20, frameon=False)  # ç§»é™¤äº†markerscale

    # æ·»åŠ ç°è‰²åŠé€æ˜ç½‘æ ¼çº¿
    plt.grid(True, color='gray', alpha=0.3)

    # å»é™¤ä¸Šè½´å’Œå³ä¾§è½´
    ax = plt.gca()
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)

    plt.tight_layout()
    plt.savefig(output_path, dpi=600)
    plt.close()
    print(f"Calibration curve saved to {output_path}")


# è°ƒç”¨å‡½æ•°ç»˜åˆ¶æ ¡å‡†æ›²çº¿
plot_calibration_curves(y_true_list, y_proba_list, set_names, output_path="calibration_curves.png")




# ==================== é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒå›¾ ====================
def plot_probability_distributions(y_true_list, y_proba_list, set_names):
    """ç»˜åˆ¶æ­£è´Ÿç±»é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒå›¾"""
    for y_true, y_proba, name in zip(y_true_list, y_proba_list, set_names):
        plt.figure(figsize=(10, 6))

        # åˆ†ç¦»æ­£è´Ÿç±»æ¦‚ç‡
        pos_proba = y_proba[y_true == 1]
        neg_proba = y_proba[y_true == 0]

        # ç»˜åˆ¶ç›´æ–¹å›¾
        plt.hist(pos_proba, bins=20, alpha=0.5, color='red', label='æ­£ç±»')
        plt.hist(neg_proba, bins=20, alpha=0.5, color='blue', label='è´Ÿç±»')

        plt.xlabel('é¢„æµ‹æ¦‚ç‡', fontsize=12)
        plt.ylabel('æ ·æœ¬æ•°é‡', fontsize=12)
        plt.title(f'{name}é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ', fontsize=14)
        plt.legend(loc='upper center', fontsize=10)
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(f"probability_distribution_{name}.png", dpi=300)
        plt.close()
    print("é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒå›¾å·²ä¿å­˜")


# è°ƒç”¨å‡½æ•°ç»˜åˆ¶æ¦‚ç‡åˆ†å¸ƒå›¾
plot_probability_distributions(y_true_list, y_proba_list, set_names)

# ================ SHAPåˆ†æ ================
# åˆ›å»ºä¿å­˜ç›®å½•
shap_dir = "shap_analysis_results"
os.makedirs(shap_dir, exist_ok=True)

# ä½¿ç”¨æœ€ç»ˆæ¨¡å‹
final_model = rf_classifier

# å‡†å¤‡è§£é‡Šæ•°æ®
X_explain = X_Test  # å½¢çŠ¶åº”ä¸º (æ ·æœ¬æ•°, ç‰¹å¾æ•°)

# éªŒè¯æ•°æ®ç»´åº¦
print("\n=== æ•°æ®éªŒè¯ ===")
print(f"ç‰¹å¾æ•°é‡: {X_explain.shape[1]}")
print(f"æ ·æœ¬æ•°é‡: {X_explain.shape[0]}")

# åˆå§‹åŒ–SHAPè§£é‡Šå™¨
explainer = shap.TreeExplainer(final_model)

# è®¡ç®—SHAPå€¼
shap_values = explainer.shap_values(X_explain)

# è°ƒè¯•è¾“å‡º
print("\n=== SHAPå€¼ç»“æ„ ===")
print(f"SHAPå€¼ç±»å‹: {type(shap_values)}")
print(f"SHAPå€¼å½¢çŠ¶: {np.array(shap_values).shape}")

# æå–æ­£ç¡®ç»´åº¦çš„SHAPå€¼ï¼ˆäºŒåˆ†ç±»åœºæ™¯ï¼‰
if isinstance(shap_values, list) and len(shap_values) == 2:
    print("\næ£€æµ‹åˆ°äºŒåˆ†ç±»æ¨¡å‹ï¼ˆåˆ—è¡¨å½¢å¼ï¼‰")
    shap_values_positive = np.array(shap_values[1])  # å½¢çŠ¶åº”ä¸º (æ ·æœ¬æ•°, ç‰¹å¾æ•°)
elif isinstance(shap_values, np.ndarray) and shap_values.ndim == 3 and shap_values.shape[2] == 2:
    print("\næ£€æµ‹åˆ°äºŒåˆ†ç±»æ¨¡å‹ï¼ˆä¸‰ç»´æ•°ç»„å½¢å¼ï¼‰")
    shap_values_positive = shap_values[:, :, 1]  # æå–æ­£ç±»çš„SHAPå€¼
else:
    print("\næ¨¡å‹å¯èƒ½æ˜¯å¤šåˆ†ç±»ï¼Œéœ€è¦è°ƒæ•´ç´¢å¼•")
    exit()

# æœ€ç»ˆç»´åº¦éªŒè¯
try:
    assert shap_values_positive.shape == X_explain.shape
except AssertionError as e:
    print(f"\n!! ç»´åº¦éªŒè¯å¤±è´¥ !!")
    print(f"SHAPå€¼å½¢çŠ¶: {shap_values_positive.shape}")
    print(f"æ•°æ®å½¢çŠ¶: {X_explain.shape}")
    print("å¯èƒ½åŸå› ï¼šæ¨¡å‹å®é™…è¾“å‡ºç»´åº¦ä¸é¢„æœŸä¸ç¬¦")
    exit()

# ================= å¯è§†åŒ– =================
# è½¬æ¢æ•°æ®æ ¼å¼
X_explain_array = X_explain.values  # è½¬æ¢ä¸ºnumpyæ•°ç»„

# è®¾ç½®å­—ä½“ä¸ºArial
plt.rcParams["font.family"] = ["Arial", "sans-serif"]

# 1. ç‰¹å¾é‡è¦æ€§å›¾
plt.figure(figsize=(12, 6))
shap.summary_plot(shap_values_positive,
                  X_explain_array,
                  feature_names=feature_names,
                  plot_type="bar",
                  show=False)
plt.title("ç‰¹å¾é‡è¦æ€§ (SHAPå€¼)", fontsize=14)
plt.tight_layout()
plt.savefig(f"{shap_dir}/1_feature_importance.png", dpi=300)
plt.close()

# 2. ç‰¹å¾æ•ˆåº”æ•£ç‚¹å›¾
plt.figure(figsize=(14, 8))
shap.summary_plot(shap_values_positive,
                  X_explain_array,
                  feature_names=feature_names,
                  show=False)
plt.title("ç‰¹å¾æ•ˆåº”å›¾", fontsize=14)
plt.tight_layout()
plt.savefig(f"{shap_dir}/2_feature_effects.png", dpi=300)
plt.close()

# 3. çƒ­åŠ›å›¾
shap_explanation = shap.Explanation(values=shap_values_positive, feature_names=feature_names, data=X_explain_array)

plt.figure(figsize=(25, 12 + len(feature_names) * 0.3))
plt.rcParams.update({
    'font.size': 6,
    'axes.titlesize': 8,
    'axes.labelsize': 5,
    'xtick.labelsize': 5,
    'ytick.labelsize': 5,
})
shap.plots.heatmap(
    shap_explanation,
    max_display=len(feature_names),
    show=False
)
plt.title("SHAPå€¼çƒ­åŠ›å›¾")

# æ‰‹åŠ¨è°ƒæ•´çƒ­åŠ›å›¾åæ ‡è½´
ax = plt.gca()
ax.set_xlabel(ax.get_xlabel(), fontsize=5)
ax.set_ylabel(ax.get_ylabel(), fontsize=5)
for tick in ax.get_xticklabels():
    tick.set_fontsize(5)
for tick in ax.get_yticklabels():
    tick.set_fontsize(4)  # ç‰¹å¾åç§°é€šå¸¸è¾ƒé•¿ï¼Œä½¿ç”¨æ›´å°çš„å­—ä½“

plt.tight_layout()
plt.subplots_adjust(left=0.4)
plt.savefig(f"{shap_dir}/3_feature_heatmap.png", dpi=300)
plt.close()

# ==================== 2. è®¡ç®—å¹¶å¯¼å‡ºæ‰€æœ‰ç‰¹å¾çš„SHAPé‡è¦æ€§åŠæƒé‡å æ¯”åˆ°Excel ====================
print("\n" + "=" * 80)
print("ã€SHAPç‰¹å¾é‡è¦æ€§åŠæƒé‡å æ¯”ï¼ˆåŸºäºSHAPå€¼ç»å¯¹å€¼å‡å€¼ï¼‰- å¯¼å‡ºè‡³Excelã€‘")
print("=" * 80)

# 2.1 è®¡ç®—SHAPç‰¹å¾é‡è¦æ€§ï¼ˆç»å¯¹å€¼å‡å€¼ï¼šæ¶ˆé™¤æ­£è´Ÿå‘æŠµæ¶ˆï¼Œåæ˜ æ€»å½±å“åŠ›ï¼‰
# ç¡®ä¿shap_values_positiveå·²é€šè¿‡ä¹‹å‰çš„SHAPåˆ†æä»£ç è®¡ç®—ï¼ˆå½¢çŠ¶ï¼š[æ ·æœ¬æ•°, ç‰¹å¾æ•°]ï¼‰
try:
    # æŒ‰ç‰¹å¾ç»´åº¦ï¼ˆaxis=0ï¼‰è®¡ç®—æ¯ä¸ªç‰¹å¾çš„SHAPå€¼ç»å¯¹å€¼å‡å€¼
    shap_importance = np.mean(np.abs(shap_values_positive), axis=0)
    feature_count = len(shap_importance)
    print(f"æˆåŠŸè®¡ç®— {feature_count} ä¸ªç‰¹å¾çš„SHAPé‡è¦æ€§\n")

    # éªŒè¯ç‰¹å¾åç§°ä¸é‡è¦æ€§æ•°é‡åŒ¹é…
    if len(feature_names) != feature_count:
        raise ValueError(f"ç‰¹å¾åç§°æ•°é‡ï¼ˆ{len(feature_names)}ï¼‰ä¸SHAPé‡è¦æ€§æ•°é‡ï¼ˆ{feature_count}ï¼‰ä¸åŒ¹é…ï¼Œè¯·æ£€æŸ¥ç‰¹å¾åˆ—è¡¨ï¼")
except NameError:
    print("é”™è¯¯ï¼šshap_values_positiveæœªå®šä¹‰ï¼Œè¯·å…ˆæ‰§è¡ŒSHAPåˆ†æä»£ç ï¼")
    exit()
except Exception as e:
    print(f"è®¡ç®—SHAPé‡è¦æ€§æ—¶å‡ºé”™ï¼š{str(e)}")
    exit()

# 2.2 è®¡ç®—æ¯ä¸ªç‰¹å¾çš„æƒé‡å æ¯”ï¼ˆå•ä¸ªç‰¹å¾SHAPé‡è¦æ€§ / æ‰€æœ‰ç‰¹å¾æ€»SHAPé‡è¦æ€§ * 100ï¼‰
total_shap_importance = np.sum(shap_importance)
# å¤„ç†æç«¯æƒ…å†µï¼ˆæ€»é‡è¦æ€§ä¸º0ï¼Œé¿å…é™¤ä»¥0é”™è¯¯ï¼‰
if total_shap_importance == 0:
    shap_importance_ratio = np.zeros_like(shap_importance)
    print("è­¦å‘Šï¼šæ‰€æœ‰ç‰¹å¾çš„SHAPé‡è¦æ€§æ€»å’Œä¸º0ï¼Œæƒé‡å æ¯”å°†å…¨éƒ¨è®¾ä¸º0\n")
else:
    shap_importance_ratio = (shap_importance / total_shap_importance) * 100  # è½¬ä¸ºç™¾åˆ†æ¯”

# 2.3 æŒ‰SHAPé‡è¦æ€§é™åºæ’åºï¼ˆç¡®ä¿æ‰€æœ‰ç‰¹å¾éƒ½è¢«åŒ…å«ï¼Œæ— é—æ¼ï¼‰
sorted_shap_idx = np.argsort(shap_importance)[::-1]  # é™åºç´¢å¼•ï¼ˆä»å¤§åˆ°å°ï¼‰
# æå–æ’åºåçš„ç‰¹å¾æ•°æ®
sorted_data = {
    "æ’å": range(1, feature_count + 1),
    "ç‰¹å¾åç§°": [feature_names[i] for i in sorted_shap_idx],
    "SHAPé‡è¦æ€§ï¼ˆç»å¯¹å€¼å‡å€¼ï¼‰": shap_importance[sorted_shap_idx],
    "æƒé‡å æ¯”(%)": shap_importance_ratio[sorted_shap_idx],
    "æƒé‡å æ¯”(æ ¼å¼åŒ–)": [f"{ratio:.2f}%" for ratio in shap_importance_ratio[sorted_shap_idx]],
    "ç´¯ç§¯æƒé‡å æ¯”(%)": np.cumsum(shap_importance_ratio[sorted_shap_idx]),  # æ–°å¢ç´¯ç§¯å æ¯”ï¼Œä¾¿äºè¯†åˆ«å…³é”®ç‰¹å¾
    "ç´¯ç§¯æƒé‡å æ¯”(æ ¼å¼åŒ–)": [f"{np.cumsum(shap_importance_ratio[sorted_shap_idx])[idx]:.2f}%"
                             for idx in range(feature_count)]
}

# 2.4 æ„å»ºå®Œæ•´DataFrameï¼ˆåŒ…å«æ‰€æœ‰ç‰¹å¾æ•°æ®ï¼‰
shap_ratio_df = pd.DataFrame(sorted_data)

# 2.5 å¯¼å‡ºåˆ°Excelï¼ˆä¼˜åŒ–æ ¼å¼ï¼šæ·»åŠ æ•°æ®è¯´æ˜ã€è°ƒæ•´åˆ—å®½ã€å†»ç»“è¡¨å¤´ï¼‰
# ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶åï¼Œé¿å…è¦†ç›–
output_excel = f"shap_feature_importance_ratio_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.xlsx"

with pd.ExcelWriter(output_excel, engine='openpyxl') as writer:
    # å·¥ä½œè¡¨1ï¼šç‰¹å¾æƒé‡å æ¯”æ•°æ®ï¼ˆä¸»è¡¨ï¼‰
    shap_ratio_df.to_excel(writer, sheet_name="ç‰¹å¾æƒé‡å æ¯”æ˜ç»†", index=False)
    # å·¥ä½œè¡¨2ï¼šæ•°æ®è¯´æ˜ï¼ˆæå‡å¯è¯»æ€§ï¼‰
    info_data = {
        "è¯´æ˜é¡¹": [
            "æ•°æ®æ¥æº",
            "SHAPé‡è¦æ€§è®¡ç®—æ–¹å¼",
            "æƒé‡å æ¯”è®¡ç®—é€»è¾‘",
            "ç´¯ç§¯æƒé‡å æ¯”å«ä¹‰",
            "æ’åºè§„åˆ™",
            "æ•°æ®ç”Ÿæˆæ—¶é—´",
            "ç‰¹å¾æ€»æ•°"
        ],
        "è¯¦ç»†è¯´æ˜": [
            "åŸºäºéšæœºæ£®æ—æ¨¡å‹çš„SHAPåˆ†æç»“æœï¼ˆæµ‹è¯•é›†æ•°æ®ï¼‰",
            "æ¯ä¸ªç‰¹å¾SHAPå€¼çš„ç»å¯¹å€¼åœ¨æ‰€æœ‰æ ·æœ¬ä¸Šçš„å‡å€¼ï¼ˆæ¶ˆé™¤æ­£è´Ÿå‘æŠµæ¶ˆï¼‰",
            "å•ä¸ªç‰¹å¾SHAPé‡è¦æ€§ / æ‰€æœ‰ç‰¹å¾SHAPé‡è¦æ€§æ€»å’Œ Ã— 100%",
            "æŒ‰é‡è¦æ€§æ’åºåï¼Œå‰Nä¸ªç‰¹å¾çš„æƒé‡å æ¯”ä¹‹å’Œï¼ˆç”¨äºè¯†åˆ«å…³é”®ç‰¹å¾ï¼‰",
            "æŒ‰SHAPé‡è¦æ€§é™åºæ’åˆ—ï¼ˆä»å½±å“æœ€å¤§åˆ°æœ€å°ï¼‰",
            pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S"),
            str(feature_count) + " ä¸ª"
        ]
    }
    info_df = pd.DataFrame(info_data)
    info_df.to_excel(writer, sheet_name="æ•°æ®è¯´æ˜", index=False)

    # ä¼˜åŒ–Excelæ ¼å¼ï¼ˆè°ƒæ•´åˆ—å®½ã€å†»ç»“è¡¨å¤´ï¼‰
    from openpyxl.styles import Font, Alignment
    from openpyxl.utils import get_column_letter

    # å¤„ç†"ç‰¹å¾æƒé‡å æ¯”æ˜ç»†"å·¥ä½œè¡¨
    ws1 = writer.sheets["ç‰¹å¾æƒé‡å æ¯”æ˜ç»†"]
    # å†»ç»“è¡¨å¤´ï¼ˆç¬¬ä¸€è¡Œï¼‰
    ws1.freeze_panes = "A2"
    # è®¾ç½®è¡¨å¤´æ ·å¼ï¼ˆåŠ ç²—ã€å±…ä¸­ï¼‰
    header_font = Font(bold=True)
    center_alignment = Alignment(horizontal="center")
    for col in range(1, len(shap_ratio_df.columns) + 1):
        cell = ws1.cell(row=1, column=col)
        cell.font = header_font
        cell.alignment = center_alignment
        # è°ƒæ•´åˆ—å®½ï¼ˆæ ¹æ®åˆ—åé•¿åº¦å’Œæ•°æ®ç±»å‹é€‚é…ï¼‰
        col_name = shap_ratio_df.columns[col - 1]
        if "ç‰¹å¾åç§°" in col_name:
            ws1.column_dimensions[get_column_letter(col)].width = 30
        elif "å æ¯”" in col_name and "æ ¼å¼åŒ–" in col_name:
            ws1.column_dimensions[get_column_letter(col)].width = 15
        elif "SHAPé‡è¦æ€§" in col_name or "å æ¯”" in col_name:
            ws1.column_dimensions[get_column_letter(col)].width = 20
        else:
            ws1.column_dimensions[get_column_letter(col)].width = 10

    # å¤„ç†"æ•°æ®è¯´æ˜"å·¥ä½œè¡¨
    ws2 = writer.sheets["æ•°æ®è¯´æ˜"]
    ws2.column_dimensions["A"].width = 15
    ws2.column_dimensions["B"].width = 80
    # è¡¨å¤´æ ·å¼
    for col in range(1, 3):
        cell = ws2.cell(row=1, column=col)
        cell.font = header_font
        cell.alignment = center_alignment

# 2.6 æ‰“å°å¯¼å‡ºç»“æœä¸æ•°æ®æ‘˜è¦
print("ğŸ“Š æ•°æ®å¯¼å‡ºæ‘˜è¦ï¼š")
print(f"   - å¯¼å‡ºæ–‡ä»¶ï¼š{output_excel}")
print(f"   - åŒ…å«ç‰¹å¾æ•°ï¼š{feature_count} ä¸ªï¼ˆæ— é—æ¼ï¼‰")
print(f"   - ExcelåŒ…å«å·¥ä½œè¡¨ï¼šã€Œç‰¹å¾æƒé‡å æ¯”æ˜ç»†ã€ã€Œæ•°æ®è¯´æ˜ã€")
print(f"   - æ˜ç»†å­—æ®µï¼šæ’åã€ç‰¹å¾åç§°ã€SHAPé‡è¦æ€§ã€æƒé‡å æ¯”ã€ç´¯ç§¯æƒé‡å æ¯”ï¼ˆå«æ ¼å¼åŒ–ç‰ˆæœ¬ï¼‰")
print("\nâœ… SHAPç‰¹å¾æƒé‡å æ¯”æ•°æ®å·²æˆåŠŸå¯¼å‡ºåˆ°Excelï¼")

# å¯é€‰ï¼šæ‰“å°å‰10ä¸ªé‡è¦ç‰¹å¾çš„é¢„è§ˆï¼ˆå¿«é€ŸæŸ¥çœ‹å…³é”®ä¿¡æ¯ï¼‰
print("\n" + "-" * 50)
print("å‰10ä¸ªé‡è¦ç‰¹å¾é¢„è§ˆï¼ˆå®Œæ•´æ•°æ®è§Excelï¼‰ï¼š")
print("-" * 50)
preview_df = shap_ratio_df[["æ’å", "ç‰¹å¾åç§°", "æƒé‡å æ¯”(æ ¼å¼åŒ–)", "ç´¯ç§¯æƒé‡å æ¯”(æ ¼å¼åŒ–)"]].head(10)
for _, row in preview_df.iterrows():
    print(
        f"æ’å{row['æ’å']:2d} | ç‰¹å¾ï¼š{row['ç‰¹å¾åç§°']:<20} | æƒé‡å æ¯”ï¼š{row['æƒé‡å æ¯”(æ ¼å¼åŒ–)']:<8} | ç´¯ç§¯å æ¯”ï¼š{row['ç´¯ç§¯æƒé‡å æ¯”(æ ¼å¼åŒ–)']}")

print(f"\nSHAPåˆ†ææˆåŠŸï¼ç»“æœä¿å­˜åœ¨ {shap_dir}/")

# ==================== è®­ç»ƒé›†å’Œæµ‹è¯•é›†é¢„æµ‹æ¦‚ç‡çš„çº¿æ€§å›å½’å›¾ ====================
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import r2_score

plt.figure(figsize=(10, 8))

# è·å–é¢„æµ‹æ¦‚ç‡ï¼ˆåˆ†ç±»æ¨¡å‹ä½¿ç”¨predict_probaè·å–æ­£ç±»æ¦‚ç‡ï¼‰
y_train_proba = final_model.predict_proba(X_Train)[:, 1]  # æ­£ç±»æ¦‚ç‡
y_test_proba = final_model.predict_proba(X_Test)[:, 1]    # æ­£ç±»æ¦‚ç‡

# å®šä¹‰é¢œè‰²å’Œæ ·å¼
train_color = '#B7DBE3'  # è®­ç»ƒé›†é¢œè‰²
test_color = '#C4C3DE'   # æµ‹è¯•é›†é¢œè‰²
trendline_colors = {
    'Train': '#2B7AB8',  # è®­ç»ƒé›†è¶‹åŠ¿çº¿é¢œè‰²ï¼ˆæ›´æ·±ï¼‰
    'Test': '#6A5ACD'    # æµ‹è¯•é›†è¶‹åŠ¿çº¿é¢œè‰²ï¼ˆæ›´æ·±ï¼‰
}

# ç»˜åˆ¶è®­ç»ƒé›†é¢„æµ‹æ¦‚ç‡æ•£ç‚¹
plt.scatter(Y_Train, y_train_proba,
            c=train_color, alpha=0.6, s=50,
            edgecolor='white', linewidth=0.5,
            label='Training Set')

# ç»˜åˆ¶æµ‹è¯•é›†é¢„æµ‹æ¦‚ç‡æ•£ç‚¹
plt.scatter(Y_Test, y_test_proba,
            c=test_color, alpha=0.6, s=50,
            edgecolor='white', linewidth=0.5,
            label='Test Set')

# æ·»åŠ è®­ç»ƒé›†æ¦‚ç‡è¶‹åŠ¿çº¿
sns.regplot(x=Y_Train, y=y_train_proba,
            scatter=False,
            line_kws={
                'color': trendline_colors['Train'],
                'linestyle': '-',
                'linewidth': 2.5,
                'alpha': 0.8
            })

# æ·»åŠ æµ‹è¯•é›†æ¦‚ç‡è¶‹åŠ¿çº¿
sns.regplot(x=Y_Test, y=y_test_proba,
            scatter=False,
            line_kws={
                'color': trendline_colors['Test'],
                'linestyle': '-',
                'linewidth': 2.5,
                'alpha': 0.8
            })

# æ·»åŠ ç†æƒ³æ ¡å‡†çº¿ï¼ˆé¢„æµ‹æ¦‚ç‡ä¸çœŸå®ç±»åˆ«å®Œå…¨åŒ¹é…ï¼‰
plt.plot([0, 1], [0, 1], 'k--', linewidth=1.5, label='Perfect Calibration')

# è®¡ç®—RÂ²åˆ†æ•°ï¼ˆè¯„ä¼°é¢„æµ‹æ¦‚ç‡ä¸çœŸå®å€¼çš„æ‹Ÿåˆç¨‹åº¦ï¼‰
train_r2 = r2_score(Y_Train, y_train_proba)
test_r2 = r2_score(Y_Test, y_test_proba)

# åˆ›å»ºè‡ªå®šä¹‰å›¾ä¾‹ï¼ŒåŒ…å«RÂ²åˆ†æ•°
legend_elements = [
    plt.Line2D([0], [0], marker='o', color='w',
               markerfacecolor=train_color, markersize=10,
               label=f'Training (RÂ²={train_r2:.3f})'),
    plt.Line2D([0], [0], marker='o', color='w',
               markerfacecolor=test_color, markersize=10,
               label=f'Test (RÂ²={test_r2:.3f})'),
    plt.Line2D([0], [0], color=trendline_colors['Train'],
               linewidth=2.5, label='Training Trend'),
    plt.Line2D([0], [0], color=trendline_colors['Test'],
               linewidth=2.5, label='Test Trend'),
    plt.Line2D([0], [0], color='k', linestyle='--',
               linewidth=1.5, label='Ideal Line')
]

plt.legend(handles=legend_elements, loc='upper left',
           frameon=True, framealpha=0.9)

# è®¾ç½®åæ ‡è½´æ ‡ç­¾å’Œæ ‡é¢˜
plt.xlabel('True Class Labels (0/1)', fontsize=12, fontweight='bold')
plt.ylabel('Predicted Probability (Class 1)', fontsize=12, fontweight='bold')
plt.title('Predicted Probability vs True Class Comparison',
          fontsize=14, fontweight='bold')

# è°ƒæ•´åæ ‡è½´èŒƒå›´å’Œåˆ»åº¦
plt.xlim(-0.05, 1.05)
plt.ylim(-0.05, 1.05)
plt.xticks([0, 0.5, 1])
plt.yticks([0, 0.5, 1])
plt.grid(True, alpha=0.2, linestyle='--')

# ç¾åŒ–å›¾å½¢ï¼šå»é™¤é¡¶éƒ¨å’Œå³ä¾§è¾¹æ¡†
ax = plt.gca()
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)

# ä¿å­˜å›¾å½¢
plt.tight_layout()
plt.savefig('probability_calibration_plot.png', dpi=300, bbox_inches='tight')
plt.close()
print("é¢„æµ‹æ¦‚ç‡æ ¡å‡†å›¾å·²ä¿å­˜ä¸º probability_calibration_plot.png")


# æ–°å¢ï¼šè®¡ç®—æŒ‡æ ‡åŠå…¶ç½®ä¿¡åŒºé—´çš„å‡½æ•°
def calculate_metrics_with_ci(model, X, y, dataset_name, metrics_functions, n_bootstraps=1000, ci_level=0.95):
    """
    è®¡ç®—æŒ‡æ ‡ç‚¹ä¼°è®¡å€¼å’Œç½®ä¿¡åŒºé—´

    å‚æ•°:
    model: è®­ç»ƒå¥½çš„æ¨¡å‹
    X: ç‰¹å¾æ•°æ® (DataFrame)
    y: çœŸå®æ ‡ç­¾ (Series)
    dataset_name: æ•°æ®é›†åç§° (str)
    metrics_functions: æŒ‡æ ‡è®¡ç®—å‡½æ•°å­—å…¸ {æŒ‡æ ‡å: å‡½æ•°}
    n_bootstraps: è‡ªåŠ©æŠ½æ ·æ¬¡æ•°
    ci_level: ç½®ä¿¡æ°´å¹³

    è¿”å›:
    åŒ…å«ç‚¹ä¼°è®¡å’Œç½®ä¿¡åŒºé—´çš„DataFrame
    """
    results = []
    n_samples = len(y)
    rng = np.random.default_rng(42)  # å›ºå®šéšæœºç§å­ç¡®ä¿å¯é‡å¤æ€§

    # å®šä¹‰è‡ªåŠ©æŠ½æ ·å‡½æ•°
    def bootstrap_sample():
        indices = rng.choice(n_samples, size=n_samples, replace=True)
        return X.iloc[indices], y.iloc[indices]

    # è®¡ç®—åŸå§‹æ•°æ®ç‚¹ä¼°è®¡
    y_proba = model.predict_proba(X)[:, 1]
    y_pred = model.predict(X)
    point_estimates = {name: func(y, y_pred, y_proba) for name, func in metrics_functions.items()}

    # è‡ªåŠ©æŠ½æ ·è®¡ç®—ç½®ä¿¡åŒºé—´
    for metric_name, metric_func in metrics_functions.items():
        bootstrap_values = []
        for _ in range(n_bootstraps):
            X_boot, y_boot = bootstrap_sample()
            y_proba_boot = model.predict_proba(X_boot)[:, 1]
            y_pred_boot = model.predict(X_boot)
            bootstrap_values.append(metric_func(y_boot, y_pred_boot, y_proba_boot))

        # è®¡ç®—ç½®ä¿¡åŒºé—´
        sorted_values = np.sort(bootstrap_values)
        lower = sorted_values[int((1 - ci_level) / 2 * n_bootstraps)]
        upper = sorted_values[int((1 + ci_level) / 2 * n_bootstraps)]

        results.append({
            'Metric': metric_name,
            'Point Estimate': point_estimates[metric_name],
            'CI Lower': lower,
            'CI Upper': upper,
            'Dataset': dataset_name  # ä½¿ç”¨æ˜¾å¼ä¼ å…¥çš„æ•°æ®é›†åç§°
        })

    return pd.DataFrame(results)


# å®šä¹‰éœ€è¦è®¡ç®—çš„æŒ‡æ ‡åŠå…¶è®¡ç®—å‡½æ•°
metrics_functions = {
    'Accuracy': lambda y, y_pred, y_proba: accuracy_score(y, y_pred),
    'AUC': lambda y, y_pred, y_proba: roc_auc_score(y, y_proba),
    'Precision': lambda y, y_pred, y_proba: precision_score(y, y_pred),
    'Recall': lambda y, y_pred, y_proba: recall_score(y, y_pred),
    'F1': lambda y, y_pred, y_proba: f1_score(y, y_pred),
    'Specificity': lambda y, y_pred, y_proba:
    confusion_matrix(y, y_pred).ravel()[0] / (
            confusion_matrix(y, y_pred).ravel()[0] + confusion_matrix(y, y_pred).ravel()[1])
}

# è®¡ç®—å„æ•°æ®é›†çš„ç½®ä¿¡åŒºé—´
# ç›´æ¥ä¼ å…¥æ•°æ®é›†åç§°ï¼Œè€Œä¸æ˜¯ä¾èµ–DataFrameçš„nameå±æ€§
ci_train = calculate_metrics_with_ci(final_model, X_Train, Y_Train, "Train", metrics_functions)
ci_val = calculate_metrics_with_ci(final_model, X_Val, Y_Val, "Validation", metrics_functions)
ci_test = calculate_metrics_with_ci(final_model, X_Test, Y_Test, "Test", metrics_functions)

# åˆå¹¶ç»“æœ
all_ci_results = pd.concat([ci_train, ci_val, ci_test], ignore_index=True)

# å†™å…¥å•ç‹¬çš„Excelæ–‡ä»¶
ci_output_path = 'metrics_confidence_intervals.xlsx'
with pd.ExcelWriter(ci_output_path, engine='openpyxl') as writer:
    # åˆ›å»ºé€è§†è¡¨ï¼ŒæŒ‰æŒ‡æ ‡å’Œæ•°æ®é›†ç»„ç»‡ç»“æœ
    pivot_table = all_ci_results.pivot_table(
        index='Metric',
        columns='Dataset',
        values=['Point Estimate', 'CI Lower', 'CI Upper']
    )

    # ç¡®ä¿åˆ—æŒ‰æœ‰æ„ä¹‰çš„é¡ºåºæ’åˆ—
    ordered_datasets = ['Train', 'Validation', 'Test']
    ordered_columns = [(metric_type, dataset)
                       for metric_type in ['Point Estimate', 'CI Lower', 'CI Upper']
                       for dataset in ordered_datasets]

    # é‡æ–°æ’åºåˆ—
    pivot_table = pivot_table[ordered_columns]

    # å†™å…¥Excel
    pivot_table.to_excel(writer, sheet_name='CI Results', float_format='%.4f')

    # æ·»åŠ å•ç‹¬çš„å·¥ä½œè¡¨ï¼ŒæŒ‰æ•°æ®é›†åˆ†å¼€
    for dataset in ['Train', 'Validation', 'Test']:
        dataset_results = all_ci_results[all_ci_results['Dataset'] == dataset]
        dataset_results = dataset_results[['Metric', 'Point Estimate', 'CI Lower', 'CI Upper']]
        dataset_results.to_excel(writer, sheet_name=f'CI_{dataset}', index=False, float_format='%.4f')

print(f"\nç½®ä¿¡åŒºé—´è®¡ç®—å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ {ci_output_path}")

# å¯é€‰ï¼šæ‰“å°ç»“æœæ‘˜è¦
print("\n=== ç½®ä¿¡åŒºé—´æ‘˜è¦ ===")
for dataset in ['Train', 'Validation', 'Test']:
    subset = all_ci_results[all_ci_results['Dataset'] == dataset]
    print(f"\n{dataset} æ•°æ®é›†:")
    for _, row in subset.iterrows():
        print(f"{row['Metric']}: {row['Point Estimate']:.4f} ({row['CI Lower']:.4f}-{row['CI Upper']:.4f})")


def calculate_metrics_with_cv(model, X, y, metrics_functions, n_splits=5, random_state=42):
    """
    æ‰§è¡Œäº”æŠ˜äº¤å‰éªŒè¯å¹¶è®¡ç®—æŒ‡æ ‡çš„ç‚¹ä¼°è®¡å’Œç½®ä¿¡åŒºé—´
    """
    # åˆå§‹åŒ–åˆ†å±‚KæŠ˜äº¤å‰éªŒè¯
    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)
    fold_results = []

    # éå†æ¯ä¸ªæŠ˜å 
    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):
        # åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›†
        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

        # æŠ˜å å†…æ ‡å‡†åŒ–ï¼ˆé¿å…æ•°æ®æ³„æ¼ï¼‰
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_val_scaled = scaler.transform(X_val)

        # è®­ç»ƒæ¨¡å‹
        model.fit(X_train_scaled, y_train)

        # é¢„æµ‹
        y_proba = model.predict_proba(X_val_scaled)[:, 1]
        y_pred = model.predict(X_val_scaled)

        # è®¡ç®—æŒ‡æ ‡
        fold_metrics = {
            "Fold": fold,
            **{name: func(y_val, y_pred, y_proba) for name, func in metrics_functions.items()}
        }
        fold_results.append(fold_metrics)

    # è½¬æ¢ä¸ºDataFrame
    fold_df = pd.DataFrame(fold_results).set_index("Fold")

    # è®¡ç®—ç‚¹ä¼°è®¡ï¼ˆå‡å€¼ï¼‰å’Œç½®ä¿¡åŒºé—´ï¼ˆåŸºäºäº¤å‰éªŒè¯ç»“æœçš„è‡ªåŠ©æ³•ï¼‰
    ci_results = []
    for metric in metrics_functions.keys():
        values = fold_df[metric].values
        point_estimate = np.mean(values)

        # ä¿®æ­£ï¼šä½¿ç”¨æ­£ç¡®çš„å‚æ•°åstatisticå’Œdata
        boot_result = bootstrap(
            data=(values,),  # æ•°æ®å‚æ•°ååº”ä¸ºdata
            statistic=lambda x: np.mean(x),  # ç»Ÿè®¡å‡½æ•°å‚æ•°ååº”ä¸ºstatistic
            n_resamples=1000,
            random_state=random_state
        )
        ci_lower, ci_upper = boot_result.confidence_interval

        ci_results.append({
            "Metric": metric,
            "Point Estimate": point_estimate,
            "CI Lower": ci_lower,
            "CI Upper": ci_upper,
            "Dataset": "5-Fold CV"
        })

    return pd.DataFrame(ci_results), fold_df


# ==================== æ‰§è¡Œäº”æŠ˜äº¤å‰éªŒè¯ ====================
# åˆå§‹åŒ–æ¨¡å‹ï¼ˆä½¿ç”¨æœ€ç»ˆç¡®å®šçš„è¶…å‚æ•°ï¼Œå¦‚n_estimators=100ï¼‰
cv_model = RandomForestClassifier(
    n_estimators=100,
    criterion='entropy',
    random_state=0,
    max_depth=10,
    min_samples_leaf=10,
    n_jobs=-1,
    class_weight='balanced'
)

# æ‰§è¡Œäº¤å‰éªŒè¯å¹¶è·å–ç»“æœ
cv_ci, cv_folds = calculate_metrics_with_cv(
    model=cv_model,
    X=X_Train,
    y=Y_Train,
    metrics_functions=metrics_functions,
    n_splits=5,
    random_state=0
)

# ==================== ä¿å­˜äº¤å‰éªŒè¯ç»“æœ ====================
# åˆ›å»ºè¾“å‡ºæ–‡ä»¶
cv_output_file = "cv_metrics_with_ci.xlsx"
with pd.ExcelWriter(cv_output_file, engine='openpyxl') as writer:
    # å†™å…¥ç½®ä¿¡åŒºé—´
    cv_ci.to_excel(writer, sheet_name="CI Summary", float_format="%.4f")

    # å†™å…¥å„æŠ˜å è¯¦ç»†ç»“æœ
    cv_folds.to_excel(writer, sheet_name="Fold Results", float_format="%.4f")

print(f"\näº”æŠ˜äº¤å‰éªŒè¯å®Œæˆï¼Œç»“æœä¿å­˜è‡³ {cv_output_file}")
print("\nå„æŠ˜å æŒ‡æ ‡è¯¦æƒ…:")
print(cv_folds)
print("\nç½®ä¿¡åŒºé—´æ‘˜è¦:")
print(cv_ci[["Metric", "Point Estimate", "CI Lower", "CI Upper"]])

