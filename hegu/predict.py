import nibabel as nib
import torch
import pandas as pd
import numpy as np
from pathlib import Path
import warnings
# å¯¼å…¥è®­ç»ƒä»£ç ä¸­å®šä¹‰çš„3D ResNetæ¨¡å‹ï¼ˆéœ€ç¡®ä¿model.pyè·¯å¾„æ­£ç¡®ï¼‰
from model import resnet18_3d

warnings.filterwarnings('ignore')


class ModelInferencePipeline:
    def __init__(self, nii_file_path, model_weight_path, inference_excel_path, patient_excel_path):
        """
        åˆå§‹åŒ–æ¨¡å‹æ¨ç†æµæ°´çº¿ï¼ˆç§»é™¤nii_file_nameç›¸å…³å¤„ç†ï¼‰
        :param nii_file_path: niiæ–‡ä»¶è·¯å¾„
        :param model_weight_path: æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚results/best_model.pthï¼‰
        :param inference_excel_path: æ¨ç†ç»“æœç‹¬ç«‹ä¿å­˜è·¯å¾„ï¼ˆåŸåŠŸèƒ½ä¿ç•™ï¼‰
        :param patient_excel_path: æ‚£è€…æ•°æ®Excelè·¯å¾„ï¼ˆpatient_periodontal_data.xlsxï¼‰
        """
        self.nii_path = Path(nii_file_path)
        self.model_weight_path = Path(model_weight_path)
        self.inference_excel_path = Path(inference_excel_path)
        self.patient_excel_path = Path(patient_excel_path)  # æ‚£è€…Excelè·¯å¾„
        self.model = None
        self.nii_data = None
        self.inference_result = None
        self.class_probabilities = None
        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

    def load_nii_data(self):
        """è¯»å–å¹¶é¢„å¤„ç†niiæ–‡ä»¶æ•°æ®ï¼ˆé€»è¾‘ä¸å˜ï¼‰"""
        try:
            if not self.nii_path.exists():
                raise FileNotFoundError(f"niiæ–‡ä»¶ä¸å­˜åœ¨: {self.nii_path}")
            if self.nii_path.suffix not in ['.nii', '.nii.gz']:
                raise ValueError(f"æ–‡ä»¶ä¸æ˜¯niiæ ¼å¼: {self.nii_path.suffix}")

            nii_img = nib.load(str(self.nii_path))
            self.nii_data = nii_img.get_fdata()  # [H, W, D]
            # é¢„å¤„ç†ï¼šé€šé“å‰ç½®+æ‰¹æ¬¡ç»´åº¦
            self.nii_data = np.expand_dims(self.nii_data, axis=0)  # [1, H, W, D]
            self.nii_data = np.expand_dims(self.nii_data, axis=0)  # [1, 1, H, W, D]
            self.nii_data = torch.tensor(self.nii_data, dtype=torch.float32)

            print(f"âœ… æˆåŠŸè¯»å–niiæ–‡ä»¶: {self.nii_path.name}")
            print(f"ğŸ“Š æ•°æ®å½¢çŠ¶ï¼ˆbatch, channel, H, W, Dï¼‰: {self.nii_data.shape}")
            return True

        except Exception as e:
            print(f"âŒ è¯»å–niiæ–‡ä»¶å¤±è´¥: {str(e)}")
            return False

    def load_model(self):
        """åŠ è½½3D ResNet18æ¨¡å‹åŠæƒé‡ï¼ˆé€»è¾‘ä¸å˜ï¼‰"""
        try:
            if not self.model_weight_path.exists():
                raise FileNotFoundError(f"æ¨¡å‹æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {self.model_weight_path}")
            if self.model_weight_path.suffix != '.pth':
                raise ValueError(f"æƒé‡æ–‡ä»¶ä¸æ˜¯.pthæ ¼å¼: {self.model_weight_path.suffix}")

            self.model = resnet18_3d(num_classes=3, in_channels=1).to(self.device)
            # å¤„ç†å¤šGPUæƒé‡é”®åé—®é¢˜
            state_dict = torch.load(str(self.model_weight_path), map_location=self.device)
            model_state_dict = self.model.state_dict()
            new_state_dict = {}
            for k, v in state_dict.items():
                new_key = k[7:] if k.startswith('module.') else k
                if new_key in model_state_dict:
                    new_state_dict[new_key] = v
                else:
                    print(f"âš ï¸  è·³è¿‡ä¸åŒ¹é…çš„æƒé‡é”®: {k}")

            self.model.load_state_dict(new_state_dict, strict=False)
            self.model.eval()

            print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹æƒé‡: {self.model_weight_path.name}")
            print(f"ğŸ’» æ¨¡å‹è¿è¡Œè®¾å¤‡: {self.device}")
            return True

        except Exception as e:
            print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {str(e)}")
            return False

    def run_inference(self):
        """è¿è¡Œæ¨¡å‹æ¨ç†ï¼ˆé€»è¾‘ä¸å˜ï¼‰"""
        try:
            if self.nii_data is None:
                raise ValueError("è¯·å…ˆè°ƒç”¨load_nii_data()åŠ è½½æ•°æ®")
            if self.model is None:
                raise ValueError("è¯·å…ˆè°ƒç”¨load_model()åŠ è½½æ¨¡å‹")

            with torch.no_grad():
                input_data = self.nii_data.to(self.device)
                logits = self.model(input_data)
                self.class_probabilities = torch.softmax(logits, dim=1).cpu().numpy()[0]
                pred_class_code = np.argmax(self.class_probabilities) + 1  # 1/2/3ç¼–ç 
                self.inference_result = pred_class_code

            print(f"\n=== æ¨ç†ç»“æœ ===")
            print(f"ğŸ“ˆ ç±»åˆ«æ¦‚ç‡:")
            print(f"   - ç±»0 (less_than_1_3): {self.class_probabilities[0]:.4f}")
            print(f"   - ç±»1 (1_3_to_2_3):   {self.class_probabilities[1]:.4f}")
            print(f"   - ç±»2 (more_than_2_3): {self.class_probabilities[2]:.4f}")
            print(f"ğŸ† é¢„æµ‹ç±»åˆ«ç¼–ç : {self.inference_result}")
            print(f"ğŸ“ ç±»åˆ«å«ä¹‰: 1=less_than_1_3, 2=1_3_to_2_3, 3=more_than_2_3")
            return True

        except Exception as e:
            print(f"âŒ æ¨ç†å¤±è´¥: {str(e)}")
            return False

    def write_to_inference_excel(self):
        """å†™å…¥ç‹¬ç«‹æ¨ç†ç»“æœExcelï¼ˆåŸåŠŸèƒ½ä¿ç•™ï¼Œä»…ç§»é™¤inference_excelä¸­çš„nii_file_nameå­—æ®µï¼‰"""
        try:
            if self.inference_result is None or self.class_probabilities is None:
                raise ValueError("è¯·å…ˆè°ƒç”¨run_inference()è·å–æ¨ç†ç»“æœ")

            result_data = {
                'inference_code': [self.inference_result],
                'inference_label': [
                    'less_than_1_3' if self.inference_result == 1 else
                    '1_3_to_2_3' if self.inference_result == 2 else
                    'more_than_2_3'
                ],
                'prob_less_than_1_3': [round(self.class_probabilities[0], 4)],
                'prob_1_3_to_2_3': [round(self.class_probabilities[1], 4)],
                'prob_more_than_2_3': [round(self.class_probabilities[2], 4)],
                'processing_time': [pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')]
            }
            result_df = pd.DataFrame(result_data)

            if self.inference_excel_path.exists():
                existing_df = pd.read_excel(str(self.inference_excel_path))
                combined_df = pd.concat([existing_df, result_df], ignore_index=True)
                combined_df.to_excel(str(self.inference_excel_path), index=False)
                print(f"\nâœ… æ¨ç†ç»“æœå·²è¿½åŠ åˆ°: {self.inference_excel_path.name}")
                print(f"ğŸ“Š æ¨ç†Excelæ€»è®°å½•æ•°: {len(combined_df)}")
            else:
                result_df.to_excel(str(self.inference_excel_path), index=False)
                print(f"\nâœ… æ–°å»ºæ¨ç†Excelå¹¶å†™å…¥: {self.inference_excel_path.name}")

            return True

        except Exception as e:
            print(f"âŒ å†™å…¥æ¨ç†Excelå¤±è´¥: {str(e)}")
            return False

    def write_to_patient_excel(self):
        """
        ä¼˜åŒ–ï¼šä»…è‡ªåŠ¨åˆ›å»ºç¼ºå¤±çš„inference_codeåˆ—ï¼Œå°†é¢„æµ‹ç±»åˆ«ç¼–ç å†™å…¥patient_periodontal_data.xlsx
        æ ¸å¿ƒé€»è¾‘ï¼šç§»é™¤nii_file_nameç›¸å…³å¤„ç†ï¼Œç›´æ¥åŸºäºç°æœ‰æ‚£è€…æ•°æ®ç»“æ„å†™å…¥æ¨ç†ç¼–ç 
        """
        try:
            # å‰ç½®æ ¡éªŒï¼šç¡®ä¿å·²è·å–æ¨ç†ç»“æœ
            if self.inference_result is None:
                raise ValueError("è¯·å…ˆè°ƒç”¨run_inference()è·å–æ¨ç†ç»“æœ")
            # å‰ç½®æ ¡éªŒï¼šç¡®ä¿æ‚£è€…Excelå­˜åœ¨
            if not self.patient_excel_path.exists():
                raise FileNotFoundError(f"æ‚£è€…Excelä¸å­˜åœ¨: {self.patient_excel_path}")

            # 1. è¯»å–æ‚£è€…Excel
            patient_df = pd.read_excel(str(self.patient_excel_path))

            # 2. ä»…è‡ªåŠ¨åˆ›å»ºç¼ºå¤±çš„inference_codeåˆ—ï¼ˆç§»é™¤nii_file_nameç›¸å…³å¤„ç†ï¼‰
            if 'inference_code' not in patient_df.columns:
                patient_df.insert(len(patient_df.columns), 'inference_code', None)  # æ’å…¥åˆ°æœ€åä¸€åˆ—
                print(f"âœ… æ‚£è€…Excelç¼ºå°‘'inference_code'åˆ—ï¼Œå·²è‡ªåŠ¨åˆ›å»ºï¼ˆåˆå§‹å€¼ä¸ºç©ºï¼‰")

            # 3. æç¤ºç”¨æˆ·é€‰æ‹©å†™å…¥è¡Œï¼ˆå› ç§»é™¤nii_file_nameåŒ¹é…ï¼Œæ”¹ä¸ºæ‰‹åŠ¨æŒ‡å®šè¡Œç´¢å¼•ï¼‰
            print(f"\nğŸ“‹ æ‚£è€…Excelå½“å‰æ•°æ®è¡Œæ•°: {len(patient_df)}")
            print("è¯·æŒ‡å®šè¦å†™å…¥inference_codeçš„è¡Œç´¢å¼•ï¼ˆä»0å¼€å§‹ï¼Œè¾“å…¥'-1'è¡¨ç¤ºè¿½åŠ æ–°è¡Œï¼‰:")
            while True:
                try:
                    target_idx = int(input("è¾“å…¥è¡Œç´¢å¼•: ").strip())
                    if target_idx == -1 or (0 <= target_idx < len(patient_df)):
                        break
                    else:
                        print(f"âŒ æ— æ•ˆç´¢å¼•ï¼è¯·è¾“å…¥0åˆ°{len(patient_df) - 1}ä¹‹é—´çš„æ•´æ•°ï¼Œæˆ–-1è¿½åŠ æ–°è¡Œ")
                except ValueError:
                    print("âŒ è¾“å…¥é”™è¯¯ï¼è¯·è¾“å…¥æ•´æ•°ç±»å‹çš„è¡Œç´¢å¼•")

            # 4. å¤„ç†ç›®æ ‡è¡Œå†™å…¥
            if target_idx == -1:
                # è¿½åŠ æ–°è¡Œï¼šä»…å¡«å……inference_codeï¼Œå…¶ä»–åˆ—ä¿æŒç©ºå€¼
                new_row = pd.DataFrame({col: [None] for col in patient_df.columns})
                new_row['inference_code'] = self.inference_result
                patient_df = pd.concat([patient_df, new_row], ignore_index=True)
                print(f"âœ… å·²è¿½åŠ æ–°è¡Œåˆ°æ‚£è€…Excelï¼ˆinference_code: {self.inference_result}ï¼‰")
            else:
                # æ›´æ–°æŒ‡å®šè¡Œï¼šä»…ä¿®æ”¹inference_codeå­—æ®µ
                old_code = patient_df.loc[target_idx, 'inference_code']
                patient_df.loc[target_idx, 'inference_code'] = self.inference_result
                print(f"âœ… å·²æ›´æ–°è¡Œç´¢å¼•{target_idx}çš„inference_code")
                print(f"   æ—§å€¼: {old_code} â†’ æ–°å€¼: {self.inference_result}")

            # 5. ä¿å­˜æ›´æ–°åçš„æ‚£è€…Excel
            patient_df.to_excel(str(self.patient_excel_path), index=False)
            print(f"âœ… æ‚£è€…Excelå·²ä¿å­˜: {self.patient_excel_path.name}")
            print(f"ğŸ“Š æ‚£è€…Excelå½“å‰æ€»è¡Œæ•°: {len(patient_df)}")
            print(f"ğŸ“‹ æ‚£è€…Excelåˆ—åˆ—è¡¨: {list(patient_df.columns)}")
            return True

        except Exception as e:
            print(f"âŒ å†™å…¥æ‚£è€…Excelå¤±è´¥: {str(e)}")
            return False


def main():
    # --------------------------
    # é…ç½®å‚æ•°ï¼ˆè¯·æ ¹æ®å®é™…è·¯å¾„ä¿®æ”¹ï¼‰
    # --------------------------
    NII_FILE_PATH = "E:/D/data_set/raw_dataset/test/CT/volume-0.nii"  # å¾…æ¨ç†niiæ–‡ä»¶
    MODEL_WEIGHT_PATH = "results/best_model.pth"  # è®­ç»ƒæœ€ä½³æƒé‡
    INFERENCE_EXCEL_PATH = "results/inference_results.xlsx"  # ç‹¬ç«‹æ¨ç†ç»“æœä¿å­˜è·¯å¾„
    PATIENT_EXCEL_PATH = "E:/D/RNN2/patient_periodontal_data.xlsx"  # ç›®æ ‡æ‚£è€…Excelï¼ˆéœ€å†™å…¥çš„æ–‡ä»¶ï¼‰

    # --------------------------
    # æ‰§è¡Œæ¨ç†æµæ°´çº¿
    # --------------------------
    print("=== 3D ResNet18 æ¨ç†æµæ°´çº¿å¯åŠ¨ ===")
    pipeline = ModelInferencePipeline(
        nii_file_path=NII_FILE_PATH,
        model_weight_path=MODEL_WEIGHT_PATH,
        inference_excel_path=INFERENCE_EXCEL_PATH,
        patient_excel_path=PATIENT_EXCEL_PATH
    )

    # æ­¥éª¤1ï¼šåŠ è½½niiæ•°æ®
    if not pipeline.load_nii_data():
        print("âŒ æµæ°´çº¿ç»ˆæ­¢ï¼ˆæ•°æ®åŠ è½½å¤±è´¥ï¼‰")
        return

    # æ­¥éª¤2ï¼šåŠ è½½æ¨¡å‹
    if not pipeline.load_model():
        print("âŒ æµæ°´çº¿ç»ˆæ­¢ï¼ˆæ¨¡å‹åŠ è½½å¤±è´¥ï¼‰")
        return

    # æ­¥éª¤3ï¼šè¿è¡Œæ¨ç†
    if not pipeline.run_inference():
        print("âŒ æµæ°´çº¿ç»ˆæ­¢ï¼ˆæ¨ç†å¤±è´¥ï¼‰")
        return

    # æ­¥éª¤4ï¼šå†™å…¥ç‹¬ç«‹æ¨ç†ç»“æœExcelï¼ˆç§»é™¤nii_file_nameå­—æ®µï¼‰
    if not pipeline.write_to_inference_excel():
        print("âš ï¸  æµæ°´çº¿è­¦å‘Šï¼ˆæ¨ç†ç»“æœå†™å…¥å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œæ‚£è€…Excelå†™å…¥ï¼‰")

    # æ­¥éª¤5ï¼šå†™å…¥æ‚£è€…Excelï¼ˆä»…å¤„ç†inference_codeï¼‰
    if not pipeline.write_to_patient_excel():
        print("âŒ æµæ°´çº¿ç»ˆæ­¢ï¼ˆæ‚£è€…Excelå†™å…¥å¤±è´¥ï¼‰")
        return

    print("\n=== æ¨ç†æµæ°´çº¿å…¨éƒ¨å®Œæˆï¼===")


if __name__ == "__main__":
    main()
